# Soft Promptå®æˆ˜æŒ‡å—ï¼šPrefix Tuning vs Prompt Tuning è½»é‡å¾®è°ƒé€‰å‹å…¨è§£æ


![Soft Promptå®æˆ˜æŒ‡å—ï¼šPrefix Tuning vs Prompt Tuning è½»é‡å¾®è°ƒé€‰å‹å…¨è§£æ - æ¶æ„å›¾](./images/fc89278e2e5847ad9c4603ff161a8f86.png)

*Soft Promptå®æˆ˜æŒ‡å—ï¼šPrefix Tuning vs Prompt Tuning è½»é‡å¾®è°ƒé€‰å‹å…¨è§£æ - ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ*


---


## PEFTæ ¸å¿ƒæŠ€æœ¯ Â· Prefix Tuning Â· Prompt Tuning Â· å¤§æ¨¡å‹å¾®è°ƒ Â· å‚æ•°é«˜æ•ˆ

**é˜…è¯»æ—¶é—´**: 30 min

> æŒæ¡Soft Promptä¸¤å¤§æ ¸å¿ƒæŠ€æœ¯ï¼Œç”¨åƒåˆ†ä¹‹ä¸€å‚æ•°é‡æ¿€æ´»ç™¾äº¿å¤§æ¨¡å‹ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚

## ç›®å½•

- [Soft Promptå…¥é—¨ï¼šä»Hard Promptåˆ°å¯å­¦ä¹ è™šæ‹ŸToken](#soft-promptå…¥é—¨ä»hard-promptåˆ°å¯å­¦ä¹ è™šæ‹Ÿtoken)
- [Prefix Tuningæ·±åº¦å®æˆ˜ï¼šTransformeræ¯å±‚æ³¨å…¥å‰ç¼€çš„ç§˜å¯†](#prefix-tuningæ·±åº¦å®æˆ˜transformeræ¯å±‚æ³¨å…¥å‰ç¼€çš„ç§˜å¯†)
- [Prompt Tuningå¿«é€Ÿä¸Šæ‰‹ï¼šè¾“å…¥å±‚è½»è£…ä¸Šé˜µçš„è§„æ¨¡æ•ˆåº”](#prompt-tuningå¿«é€Ÿä¸Šæ‰‹è¾“å…¥å±‚è½»è£…ä¸Šé˜µçš„è§„æ¨¡æ•ˆåº”)
- [å¯¹æ¯”ä¸é€‰å‹ï¼šå¤§æ¨¡å‹ç”¨Promptï¼Œå°æ¨¡å‹ç”¨Prefixçš„å®è·µæ³•åˆ™](#å¯¹æ¯”ä¸é€‰å‹å¤§æ¨¡å‹ç”¨promptï¼Œå°æ¨¡å‹ç”¨prefixçš„å®è·µæ³•åˆ™)


---


éšç€å¤§æ¨¡å‹å‚æ•°è§„æ¨¡çˆ†ç‚¸å¼å¢é•¿ï¼Œä¼ ç»Ÿå…¨é‡å¾®è°ƒï¼ˆFull Fine-tuningï¼‰å› æ˜¾å­˜ä¸ç®—åŠ›æˆæœ¬è¿‡é«˜å·²éš¾ä»¥ä¸ºç»§ã€‚å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æŠ€æœ¯åº”è¿è€Œç”Ÿï¼Œå…¶ä¸­Soft Promptæ–¹æ¡ˆâ€”â€”ç‰¹åˆ«æ˜¯Prefix Tuningä¸Prompt Tuningâ€”â€”å‡­å€Ÿæä½çš„å‚æ•°å¼€é”€å’Œä¼˜å¼‚çš„ä»»åŠ¡é€‚é…èƒ½åŠ›ï¼Œæˆä¸ºå·¥ä¸šè½åœ°é¦–é€‰ã€‚æœ¬æ–‡é¢å‘ä¸­çº§å¼€å‘è€…ï¼Œç³»ç»Ÿæ‹†è§£ä¸¤å¤§æŠ€æœ¯çš„æ ¸å¿ƒåŸç†ã€å®ç°è·¯å¾„ä¸é€‰å‹ç­–ç•¥ï¼ŒåŠ©ä½ å¿«é€ŸæŒæ¡è½»é‡åŒ–å¾®è°ƒåˆ©å™¨ã€‚


---


## Soft Promptå…¥é—¨ï¼šä»Hard Promptåˆ°å¯å­¦ä¹ è™šæ‹ŸToken

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„å›°å¢ƒï¼šç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯ï¼ˆPromptï¼‰åœ¨æŸä¸ªä»»åŠ¡ä¸Šè¡¨ç°æƒŠè‰³ï¼Œæ¢ä¸€ä¸ªç›¸ä¼¼åœºæ™¯å´æ•ˆæœéª¤é™ï¼Ÿæˆ–è€…å›¢é˜Ÿé‡Œä¸åŒæˆå‘˜å†™çš„æç¤ºè¯é£æ ¼è¿¥å¼‚ï¼Œæ¨¡å‹è¾“å‡ºå¿½é«˜å¿½ä½ï¼Œè°ƒè¯•èµ·æ¥åƒåœ¨â€œç„å­¦ç‚¼ä¸¹â€ï¼Ÿè¿™ä¸æ˜¯ä½ çš„é”™â€”â€”è¿™æ˜¯ä¼ ç»Ÿ Hard Prompt çš„å¤©ç„¶å±€é™ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œçº¿ä¸Šçªç„¶æ¥äº†ä¸ªæ–°ä»»åŠ¡ï¼Œä½ ä¸å¾—ä¸ç†¬å¤œé‡å†™å‡ åæ¡æç¤ºè¯æ¨¡æ¿ï¼Œç»“æœç¬¬äºŒå¤©æ¨¡å‹è¿˜æ˜¯â€œä¸å¬è¯â€ã€‚æœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•ï¼Œèƒ½è®©æç¤ºè¯è‡ªå·±â€œå­¦ä¼šé€‚åº”â€ï¼Œè€Œä¸æ˜¯é äººå·¥åå¤è¯•é”™ï¼Ÿ

ç­”æ¡ˆå°±æ˜¯ Soft Prompt â€”â€” ä¸€ç§è®©æç¤ºè¯ä»â€œå†™æ­»çš„æŒ‡ä»¤â€è¿›åŒ–ä¸ºâ€œä¼šå­¦ä¹ çš„å‘å¯¼â€çš„è½»é‡åŒ–å¾®è°ƒæŠ€æœ¯ã€‚å®ƒä¸å†ä¾èµ–äººç±»è¯­è¨€å·¥ç¨‹å¸ˆçš„ç›´è§‰ï¼Œè€Œæ˜¯å°†æç¤ºè½¬åŒ–ä¸ºä¸€ç»„å¯è®­ç»ƒçš„åµŒå…¥å‘é‡ï¼Œé€šè¿‡åå‘ä¼ æ’­è‡ªåŠ¨ä¼˜åŒ–ï¼Œç²¾å‡†é€‚é…ç›®æ ‡ä»»åŠ¡ã€‚è¿™ä¸ä»…æ˜¯å·¥ç¨‹æ•ˆç‡çš„é£è·ƒï¼Œæ›´æ˜¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„ä¸€æ¬¡å…³é”®è·ƒè¿ã€‚


---


### å›é¡¾Hard Promptçš„ä¸‰å¤§ç—›ç‚¹

åœ¨æ·±å…¥ Soft Prompt ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆå›é¡¾ä¸€ä¸‹ä¼ ç»Ÿ Hard Prompt çš„æ ¸å¿ƒé—®é¢˜ï¼š

1. **ä¾èµ–äººå·¥è®¾è®¡**ï¼šæ¯ä¸ªä»»åŠ¡éƒ½éœ€è¦ä¸“å®¶æ‰‹åŠ¨æ’°å†™ã€è°ƒè¯•æç¤ºè¯ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥è§„æ¨¡åŒ–ã€‚
2. **æ³›åŒ–æ€§å·®**ï¼šåŒä¸€ç»„æç¤ºè¯åœ¨ç›¸ä¼¼ä½†éç›¸åŒä»»åŠ¡ä¸Šå¯èƒ½å®Œå…¨å¤±æ•ˆï¼Œç¼ºä¹è¿ç§»èƒ½åŠ›ã€‚
3. **æ•ˆæœä¸ç¨³å®š**ï¼šå¾®å°çš„æªè¾å˜åŒ–ï¼ˆå¦‚â€œè¯·æ€»ç»“â€ vs â€œè¯·ç®€è¦æ¦‚æ‹¬â€ï¼‰å¯èƒ½å¯¼è‡´è¾“å‡ºè´¨é‡å‰§çƒˆæ³¢åŠ¨ã€‚

> âš ï¸ æ³¨æ„: Hard Prompt çš„æœ¬è´¨æ˜¯â€œé™æ€å­—ç¬¦ä¸²æ³¨å…¥â€ï¼Œæ¨¡å‹æ— æ³•æ„ŸçŸ¥å…¶è¯­ä¹‰æƒé‡æˆ–ä»»åŠ¡ç›¸å…³æ€§ï¼Œåªèƒ½è¢«åŠ¨æ¥å—ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œåœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­ï¼Œä½ å¯èƒ½ä¼šå†™ï¼šâ€œåˆ¤æ–­ä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼šæ­£é¢ã€è´Ÿé¢æˆ–ä¸­æ€§ã€‚â€ä½†åœ¨äº§å“è¯„è®ºåœºæ™¯ä¸‹ï¼Œç”¨æˆ·è¯­è¨€æ›´å£è¯­åŒ–ï¼ŒåŸæç¤ºè¯å¯èƒ½å¼•å¯¼æ¨¡å‹å¿½ç•¥ä¿šè¯­æˆ–è®½åˆºè¯­æ°”ï¼Œå¯¼è‡´è¯¯åˆ¤ã€‚äººå·¥è°ƒæ•´è´¹æ—¶è´¹åŠ›ï¼Œä¸”ç¼ºä¹ç³»ç»Ÿæ€§ä¼˜åŒ–è·¯å¾„ã€‚


---


### Soft Promptçš„æ ¸å¿ƒæ€æƒ³ï¼šæç¤ºè¯å³å‚æ•°

Soft Prompt çš„é©å‘½æ€§åœ¨äºâ€”â€”**æŠŠæç¤ºè¯ä»â€œå­—ç¬¦ä¸²â€å˜æˆâ€œå¯è®­ç»ƒçš„åµŒå…¥å‘é‡â€**ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä¸å†å‘æ¨¡å‹è¾“å…¥åƒ â€œPlease summarize: â€ è¿™æ ·çš„è‡ªç„¶è¯­è¨€ Tokenï¼Œè€Œæ˜¯ç›´æ¥åœ¨è¾“å…¥å±‚æ‹¼æ¥ä¸€ç»„éšæœºåˆå§‹åŒ–çš„å‘é‡ï¼ˆç§°ä¸ºâ€œè™šæ‹ŸTokenâ€ï¼‰ï¼Œè¿™äº›å‘é‡ä¸å¯¹åº”ä»»ä½•çœŸå®è¯æ±‡ï¼Œå´èƒ½åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡æ¢¯åº¦ä¸‹é™ä¸æ–­è°ƒæ•´ï¼Œæœ€ç»ˆå­¦ä¼šå¦‚ä½•â€œå¼•å¯¼â€æ¨¡å‹å®Œæˆç‰¹å®šä»»åŠ¡ã€‚

ç±»æ¯”ç†è§£ï¼šå¦‚æœæŠŠå¤§æ¨¡å‹æ¯”ä½œä¸€ä¸ªç»éªŒä¸°å¯Œçš„å¨å¸ˆï¼ŒHard Prompt å°±åƒä½ å£å¤´å‘Šè¯‰ä»–â€œåšä¸€é“è¾£èœâ€ï¼Œè€Œ Soft Prompt åˆ™æ˜¯ä½ ç»™ä»–ä¸€å¥—å¯è°ƒèŠ‚çš„è°ƒæ–™é…æ–¹â€”â€”ç›å¤šå°‘å…‹ã€è¾£æ¤’å‡ å‹ºâ€”â€”è¿™å¥—é…æ–¹ä¼šæ ¹æ®é£Ÿå®¢åé¦ˆï¼ˆæŸå¤±å‡½æ•°ï¼‰è‡ªåŠ¨ä¼˜åŒ–ï¼Œæœ€ç»ˆåšå‡ºæœ€ç¬¦åˆå£å‘³çš„èœã€‚

```mermaid
flowchart TB
    A[äººå·¥è®¾è®¡Hard Prompt] --> B{æ˜¯å¦å¯å­¦ä¹ ?}
    B -->|å¦| C[é™æ€å­—ç¬¦ä¸²æ³¨å…¥\nä¾èµ–ä¸“å®¶ç»éªŒ\næ³›åŒ–æ€§å·®]
    B -->|æ˜¯| D[åˆå§‹åŒ–Soft PromptåµŒå…¥å‘é‡\nè™šæ‹ŸTokenæ— çœŸå®è¯æ±‡å¯¹åº”]
    D --> E[æ‹¼æ¥è‡³æ¨¡å‹è¾“å…¥å±‚]
    E --> F[åå‘ä¼ æ’­ä¼˜åŒ–åµŒå…¥å‚æ•°]
    F --> G[è‡ªåŠ¨é€‚é…ç›®æ ‡ä»»åŠ¡\næå‡æ³›åŒ–ä¸ç¨³å®šæ€§]
```

*ä»Hard Promptåˆ°Soft Promptçš„æ¼”è¿›æµç¨‹ï¼šäººå·¥è®¾è®¡â†’å¯å­¦ä¹ åµŒå…¥â†’åå‘ä¼ æ’­ä¼˜åŒ–*


---


### è™šæ‹ŸTokenå¦‚ä½•è‡ªæˆ‘è¿›åŒ–ï¼Ÿ

Soft Prompt çš„è®­ç»ƒæœºåˆ¶éå¸¸ä¼˜é›…ï¼š

1. **åˆå§‹åŒ–**ï¼šåœ¨è¾“å…¥åºåˆ—å‰æ·»åŠ  `n` ä¸ªå¯å­¦ä¹ çš„åµŒå…¥å‘é‡ï¼ˆä¾‹å¦‚ `n=10`ï¼‰ï¼Œç»´åº¦ä¸æ¨¡å‹è¯åµŒå…¥ä¸€è‡´ã€‚
2. **å‰å‘ä¼ æ’­**ï¼šå°†è™šæ‹ŸTokenä¸çœŸå®è¾“å…¥æ‹¼æ¥ï¼Œé€å…¥é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¾—åˆ°è¾“å‡ºã€‚
3. **è®¡ç®—æŸå¤±**ï¼šæ ¹æ®ä»»åŠ¡ç›®æ ‡ï¼ˆå¦‚åˆ†ç±»å‡†ç¡®ç‡ã€ç”ŸæˆBLEUåˆ†ï¼‰è®¡ç®—æŸå¤±å‡½æ•°ã€‚
4. **åå‘ä¼ æ’­**ï¼šä»…æ›´æ–°è™šæ‹ŸTokençš„åµŒå…¥å‚æ•°ï¼Œå†»ç»“åŸå§‹æ¨¡å‹æ‰€æœ‰å‚æ•°ã€‚
5. **è¿­ä»£ä¼˜åŒ–**ï¼šé‡å¤æ­¥éª¤2-4ï¼Œç›´åˆ°è™šæ‹ŸTokenæ”¶æ•›è‡³æœ€ä¼˜å¼•å¯¼çŠ¶æ€ã€‚

è¿™ä¸ªè¿‡ç¨‹è®©è™šæ‹ŸTokené€æ­¥â€œå†…åŒ–â€ä»»åŠ¡éœ€æ±‚ã€‚æ¯”å¦‚åœ¨æ–‡æœ¬æ‘˜è¦ä»»åŠ¡ä¸­ï¼Œå®ƒä»¬å¯èƒ½å­¦ä¼šå¼ºè°ƒâ€œä¿ç•™ä¸»è¯­+åŠ¨è¯ç»“æ„â€ï¼Œè€Œåœ¨é—®ç­”ä»»åŠ¡ä¸­ï¼Œåˆ™å¯èƒ½èšç„¦â€œå®šä½ç–‘é—®è¯+å®ä½“åŒ¹é…â€ã€‚

```python
import torch
import torch.nn as nn

class SoftPromptModel(nn.Module):
    """
    å®ç° Soft Prompt åˆå§‹åŒ–ä¸æ‹¼æ¥çš„ç¤ºä¾‹æ¨¡å‹
    æ”¯æŒå°†å¯å­¦ä¹ çš„è™šæ‹Ÿ token æ‹¼æ¥åˆ°è¾“å…¥åµŒå…¥å‰
    
    Args:
        vocab_size (int): è¯è¡¨å¤§å°ï¼Œç”¨äº Embedding å±‚
        embed_dim (int): åµŒå…¥ç»´åº¦ï¼Œå¦‚ 768 æˆ– 1024
        prompt_length (int): Soft Prompt çš„ token æ•°é‡
    
    Returns:
        æ‹¼æ¥åçš„åµŒå…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º [batch_size, seq_len + prompt_length, embed_dim]
    """
    def __init__(self, vocab_size, embed_dim, prompt_length):
        super(SoftPromptModel, self).__init__()
        # Step 1: åˆå§‹åŒ–è¯åµŒå…¥å±‚
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        
        # Step 2: åˆå§‹åŒ–å¯å­¦ä¹ çš„ Soft Prompt å‚æ•°ï¼ˆè™šæ‹Ÿ tokenï¼‰
        self.soft_prompt = nn.Parameter(torch.randn(prompt_length, embed_dim))
        
        # Step 3: ä¿å­˜ prompt é•¿åº¦ï¼Œä¾¿äºåç»­æ‹¼æ¥
        self.prompt_length = prompt_length
    
    def forward(self, input_ids):
        """
        å‰å‘ä¼ æ’­ï¼šå°† Soft Prompt ä¸è¾“å…¥åµŒå…¥æ‹¼æ¥
        
        Args:
            input_ids (Tensor): è¾“å…¥ token IDï¼Œå½¢çŠ¶ [batch_size, seq_len]
        
        Returns:
            combined_embeds (Tensor): æ‹¼æ¥ååµŒå…¥ï¼Œ[batch_size, seq_len + prompt_length, embed_dim]
        """
        # Step 4: è·å–è¾“å…¥ token çš„åµŒå…¥è¡¨ç¤º
        input_embeds = self.embedding(input_ids)  # å½¢çŠ¶: [batch_size, seq_len, embed_dim]
        
        # Step 5: æ‰©å±• Soft Prompt ä»¥åŒ¹é… batch ç»´åº¦
        batch_size = input_ids.size(0)
        soft_prompt_expanded = self.soft_prompt.unsqueeze(0).expand(batch_size, -1, -1)  # [batch_size, prompt_length, embed_dim]
        
        # Step 6: åœ¨åºåˆ—ç»´åº¦æ‹¼æ¥ Soft Prompt ä¸åŸå§‹è¾“å…¥åµŒå…¥
        combined_embeds = torch.cat([soft_prompt_expanded, input_embeds], dim=1)  # [batch_size, prompt_length + seq_len, embed_dim]
        
        # Step 7: è¿”å›æ‹¼æ¥ç»“æœ
        return combined_embeds

# Step 8: ç¤ºä¾‹è°ƒç”¨ä¸æµ‹è¯•

if __name__ == "__main__":
    # Step 9: è®¾ç½®è¶…å‚æ•°
    VOCAB_SIZE = 50000   # è¯è¡¨å¤§å°
    EMBED_DIM = 768      # åµŒå…¥ç»´åº¦
    PROMPT_LENGTH = 10   # Soft Prompt é•¿åº¦
    BATCH_SIZE = 4       # æ‰¹æ¬¡å¤§å°
    SEQ_LEN = 20         # è¾“å…¥åºåˆ—é•¿åº¦
    
    # Step 10: åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = SoftPromptModel(VOCAB_SIZE, EMBED_DIM, PROMPT_LENGTH)
    
    # Step 11: ç”Ÿæˆæ¨¡æ‹Ÿè¾“å…¥ token IDs
    input_ids = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN))
    
    # Step 12: å‰å‘ä¼ æ’­è·å–æ‹¼æ¥åçš„åµŒå…¥
    output_embeds = model(input_ids)
    
    # Step 13: æ‰“å°è¾“å‡ºå½¢çŠ¶éªŒè¯
    print(f"Input shape: {input_ids.shape}")
    print(f"Output shape: {output_embeds.shape}")
    print(f"Soft Prompt parameters shape: {model.soft_prompt.shape}")
```

#### OUTPUT

```
Input shape: torch.Size([4, 20])
Output shape: torch.Size([4, 30, 768])
Soft Prompt parameters shape: torch.Size([10, 768])
```

è¯¥ä»£ç æ¼”ç¤ºäº†å¦‚ä½•åœ¨ PyTorch ä¸­å®ç° Soft Prompt çš„åˆå§‹åŒ–ä¸æ‹¼æ¥ã€‚æ ¸å¿ƒæ˜¯åˆ›å»ºä¸€ä¸ªå¯å­¦ä¹ çš„å‚æ•°çŸ©é˜µ `soft_prompt`ï¼Œå…¶å½¢çŠ¶ä¸º `[prompt_length, embed_dim]`ï¼Œä»£è¡¨è™šæ‹Ÿ token çš„åµŒå…¥å‘é‡ã€‚åœ¨å‰å‘ä¼ æ’­ä¸­ï¼Œè¯¥çŸ©é˜µè¢«æ‰©å±•åˆ°æ‰¹æ¬¡ç»´åº¦å¹¶ä¸åŸå§‹è¾“å…¥åµŒå…¥åœ¨åºåˆ—ç»´åº¦æ‹¼æ¥ï¼Œä»è€Œåœ¨æ¯ä¸ªæ ·æœ¬å‰æ·»åŠ å¯è®­ç»ƒçš„æç¤ºä¿¡æ¯ã€‚è¿™ç§æŠ€æœ¯å…è®¸æ¨¡å‹åœ¨ä¸ä¿®æ”¹ä¸»å¹²ç½‘ç»œç»“æ„çš„å‰æä¸‹ï¼Œé€šè¿‡ä¼˜åŒ–è™šæ‹Ÿ token æ¥å¼•å¯¼ç”Ÿæˆæˆ–åˆ†ç±»è¡Œä¸ºã€‚

è¾“å‡ºç»“æœæ˜¾ç¤ºè¾“å…¥åºåˆ—é•¿åº¦ 20 è¢«æ‰©å±•ä¸º 30ï¼ˆ20 + 10ï¼‰ï¼Œè¡¨æ˜ Soft Prompt æˆåŠŸå‰ç½®æ‹¼æ¥ã€‚æ­¤æ–¹æ³•æ˜¯ Hard Prompt åˆ°å¯å­¦ä¹ æç¤ºçš„å…³é”®è¿‡æ¸¡ï¼Œå¸¸ç”¨äº Prompt Tuning å’Œ Prefix Tuning ç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ä¸­ã€‚


---


### Soft Promptåœ¨PEFTç”Ÿæ€ä¸­çš„æˆ˜ç•¥ä»·å€¼

ä½œä¸º Parameter-Efficient Fine-Tuningï¼ˆPEFTï¼‰æŠ€æœ¯å®¶æ—çš„é‡è¦æˆå‘˜ï¼ŒSoft Prompt å…·æœ‰ä¸å¯æ›¿ä»£çš„ä¼˜åŠ¿ï¼š

- **æä½å‚æ•°å¼€é”€**ï¼šé€šå¸¸åªè®­ç»ƒå‡ ååˆ°å‡ ç™¾ä¸ªTokençš„åµŒå…¥ï¼Œç›¸æ¯”å…¨å‚æ•°å¾®è°ƒèŠ‚çœ99%+æ˜¾å­˜ã€‚
- **æ¨¡å—åŒ–éƒ¨ç½²**ï¼šä¸åŒä»»åŠ¡çš„Soft Promptå¯ç‹¬ç«‹ä¿å­˜ã€åŠ è½½ï¼Œå®ç°â€œä¸€ä¸ªæ¨¡å‹ï¼Œå¤šå¥—æç¤ºâ€ã€‚
- **é›¶æ ·æœ¬å‹å¥½**ï¼šå³ä½¿é¢å¯¹æœªè§è¿‡çš„ä»»åŠ¡ç±»å‹ï¼ŒSoft Prompt ä¹Ÿèƒ½é€šè¿‡å°‘é‡æ ·æœ¬å¿«é€Ÿé€‚é…ã€‚

æ›´é‡è¦çš„æ˜¯ï¼Œå®ƒä¸ºåç»­çš„ Prefix Tuningã€Adapterã€LoRA ç­‰æŠ€æœ¯é“ºå¹³äº†é“è·¯â€”â€”è¯æ˜äº†â€œå±€éƒ¨å‚æ•°è°ƒæ•´å³å¯æ¿€æ´»å…¨å±€èƒ½åŠ›â€çš„å¯è¡Œæ€§ã€‚

> Soft Promptè®©æç¤ºè¯ä»â€˜å†™æ­»çš„æŒ‡ä»¤â€™å˜æˆâ€˜ä¼šå­¦ä¹ çš„å‘å¯¼â€™ï¼Œæ˜¯è½»é‡åŒ–å¾®è°ƒçš„å…³é”®è·ƒè¿ã€‚


---


ä¸‹ä¸€ç« èŠ‚ã€ŠPrefix Tuningæ·±åº¦å®æˆ˜ï¼šTransformeræ¯å±‚æ³¨å…¥å‰ç¼€çš„ç§˜å¯†ã€‹å°†å¸¦ä½ æ·±å…¥Transformerå†…éƒ¨ï¼Œæ¢ç´¢å¦‚ä½•åœ¨æ¯ä¸€å±‚æ³¨æ„åŠ›æœºåˆ¶å‰åŠ¨æ€æ³¨å…¥å¯å­¦ä¹ å‰ç¼€ï¼Œå®ç°æ›´ç²¾ç»†çš„çŠ¶æ€å¼•å¯¼ä¸ä¸Šä¸‹æ–‡æ§åˆ¶ã€‚å‡†å¤‡å¥½æ­å¼€æ·±å±‚æç¤ºå·¥ç¨‹çš„é¢çº±äº†å—ï¼Ÿ


---


## Prefix Tuningæ·±åº¦å®æˆ˜ï¼šTransformeræ¯å±‚æ³¨å…¥å‰ç¼€çš„ç§˜å¯†

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„å›°å¢ƒï¼šæ¨¡å‹å‚æ•°åŠ¨è¾„ä¸Šäº¿ï¼Œå¾®è°ƒæˆæœ¬é«˜åˆ°ç¦»è°±ï¼Œä½†ä¸šåŠ¡åœºæ™¯åˆè¦æ±‚ç”Ÿæˆè´¨é‡å¿…é¡»ç²¾å‡†å¯æ§ï¼Ÿæƒ³è±¡ä¸€ä¸‹ï¼Œçº¿ä¸Šçªç„¶éœ€è¦è®©ä¸€ä¸ª7Bçš„å°æ¨¡å‹å†™å‡ºç¬¦åˆå“ç‰Œè°ƒæ€§çš„å¹¿å‘Šæ–‡æ¡ˆâ€”â€”å…¨é‡å¾®è°ƒæ˜¾å­˜çˆ†ç‚¸ï¼ŒPrompt Engineeringæ•ˆæœé£˜å¿½ï¼Œéš¾é“åªèƒ½å¦¥åï¼Ÿ

åˆ«æ€¥ã€‚Prefix Tuning å°±æ˜¯ä¸ºè¿™ç§â€œæ—¢è¦åˆè¦â€åœºæ™¯è€Œç”Ÿçš„ç‚¼é‡‘æœ¯ã€‚

> ğŸ” **æ­£å¼å®šä¹‰**ï¼šPrefix Tuning æ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰æ–¹æ³•ï¼Œå®ƒé€šè¿‡åœ¨ Transformer æ¯ä¸€å±‚çš„è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­æ’å…¥å¯å­¦ä¹ çš„å‰ç¼€ Key/Value çŸ©é˜µï¼ˆPrefix Key / Prefix Valueï¼‰ï¼Œå¼•å¯¼æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å…³æ³¨ç‰¹å®šè¯­ä¹‰æ–¹å‘ï¼Œè€Œæ— éœ€ä¿®æ”¹åŸå§‹æ¨¡å‹æƒé‡ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯â€œæ“çºµæ³¨æ„åŠ›ç¼“å­˜â€ï¼Œè€Œéæ”¹å˜æ¨¡å‹ç»“æ„æˆ–è¾“å…¥åµŒå…¥ã€‚

ä¸åŒç±»æŠ€æœ¯å¯¹æ¯”ï¼š

| æ–¹æ³•            | å‚æ•°ä½ç½®             | å¯è®­ç»ƒå‚æ•°å æ¯” | æ˜¯å¦ä¿®æ”¹æ¨¡å‹ç»“æ„ | é€‚ç”¨ä»»åŠ¡ç±»å‹         | å…¸å‹å‰ç¼€/Adapteré•¿åº¦ |
|-----------------|----------------------|----------------|------------------|----------------------|------------------------|
| **Prefix Tuning** | æ¯å±‚Attentionçš„K/Vå‰ | ~0.1%~1%       | å¦               | ç”Ÿæˆã€é£æ ¼æ§åˆ¶ã€å¯¹è¯ | 5~20 tokens           |
| Prompt Tuning   | ä»…è¾“å…¥å±‚åµŒå…¥å‰        | ~0.01%~0.1%    | å¦               | åˆ†ç±»ã€QAã€å¤§æ¨¡å‹ç”Ÿæˆ | 10~100 tokens         |
| Adapter Tuning  | æ¯å±‚FFNåæ’å…¥Adapter  | ~0.5%~3%       | æ˜¯ï¼ˆæ’å…¥æ¨¡å—ï¼‰   | å¤šä»»åŠ¡ã€è¿ç§»å­¦ä¹      | éšè—å±‚ç»´åº¦ 64~512     |
| LoRA            | æ³¨æ„åŠ›Q/K/VçŸ©é˜µä½ç§©åˆ†è§£ | ~0.05%~0.5%    | å¦ï¼ˆçŸ©é˜µæ›¿æ¢ï¼‰   | é€šç”¨å¾®è°ƒã€å¤šè¯­è¨€     | ç§© r=4~64             |

> ğŸ’¡ æ ¸å¿ƒåŒºåˆ«ï¼šPrefix Tuning çš„â€œæ¸—é€æ€§â€æœ€å¼ºâ€”â€”å®ƒåœ¨æ¯ä¸€å±‚éƒ½æ¤å…¥å¼•å¯¼ä¿¡å·ï¼Œç›´æ¥å½±å“æ³¨æ„åŠ›æœºåˆ¶ï¼›è€Œ Prompt Tuning ä»…ä½œç”¨äºè¾“å…¥å±‚ï¼ŒAdapter åˆ™æ’å…¥é¢å¤–è®¡ç®—æ¨¡å—ã€‚å› æ­¤ï¼ŒPrefix åœ¨å°æ¨¡å‹ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°æ›´ä¼˜ï¼Œä½†ä¼˜åŒ–éš¾åº¦æ›´é«˜ã€‚


---


### æ·±å±‚æ¶æ„è§£å‰–ï¼šå‰ç¼€çŸ©é˜µå¦‚ä½•å±‚å±‚æ¸—é€

ä¼ ç»ŸSoft Promptåªåœ¨è¾“å…¥å±‚åŠ è™šæ‹ŸTokenï¼Œè€ŒPrefix Tuningåˆ™å¤§èƒ†å¾—å¤šâ€”â€”å®ƒåœ¨**æ¯ä¸€å±‚Transformerçš„è‡ªæ³¨æ„åŠ›æ¨¡å—å‰**ï¼Œéƒ½æ’å…¥ä¸€å¯¹å¯å­¦ä¹ çš„å‰ç¼€çŸ©é˜µï¼ˆPrefix Key å’Œ Prefix Valueï¼‰ã€‚è¿™äº›çŸ©é˜µä¸æ˜¯ç®€å•æ‹¼æ¥ï¼Œè€Œæ˜¯ç›´æ¥å‚ä¸æ³¨æ„åŠ›è®¡ç®—ï¼Œé‡å¡‘æ¯ä¸€å±‚å¯¹ä¸Šä¸‹æ–‡çš„ç†è§£è·¯å¾„ã€‚

```mermaid
flowchart TB
    subgraph è¾“å…¥å±‚["è¾“å…¥åµŒå…¥å±‚"]
        I[åŸå§‹è¾“å…¥Token Embedding]
    end
    subgraph ç¬¬1å±‚Transformer["ç¬¬1å±‚ Transformer"]
        A1[è‡ªæ³¨æ„åŠ›æ¨¡å—]
        P1K[å¯å­¦ä¹ å‰ç¼€Key_1]
        P1V[å¯å­¦ä¹ å‰ç¼€Value_1]
        A1 -->|æ‹¼æ¥| PKV1[ä¿®æ”¹åçš„K/Vç¼“å­˜]
        P1K --> PKV1
        P1V --> PKV1
    end
    subgraph ç¬¬2å±‚Transformer["ç¬¬2å±‚ Transformer"]
        A2[è‡ªæ³¨æ„åŠ›æ¨¡å—]
        P2K[å¯å­¦ä¹ å‰ç¼€Key_2]
        P2V[å¯å­¦ä¹ å‰ç¼€Value_2]
        A2 -->|æ‹¼æ¥| PKV2[ä¿®æ”¹åçš„K/Vç¼“å­˜]
        P2K --> PKV2
        P2V --> PKV2
    end
    subgraph ç¬¬Nå±‚Transformer["ç¬¬Nå±‚ Transformer"]
        AN[è‡ªæ³¨æ„åŠ›æ¨¡å—]
        PNK[å¯å­¦ä¹ å‰ç¼€Key_N]
        PNV[å¯å­¦ä¹ å‰ç¼€Value_N]
        AN -->|æ‹¼æ¥| PKVN[ä¿®æ”¹åçš„K/Vç¼“å­˜]
        PNK --> PKVN
        PNV --> PKVN
    end
    I --> A1
    A1 --> A2
    A2 --> AN
    style P1K fill:#cce5ff,stroke:#3399ff
    style P1V fill:#cce5ff,stroke:#3399ff
    style P2K fill:#cce5ff,stroke:#3399ff
    style P2V fill:#cce5ff,stroke:#3399ff
    style PNK fill:#cce5ff,stroke:#3399ff
    style PNV fill:#cce5ff,stroke:#3399ff
```

*Prefix Tuningæ¶æ„å›¾ï¼šåœ¨æ¯å±‚Transformerçš„è‡ªæ³¨æ„åŠ›æ¨¡å—ä¸­æ’å…¥å¯å­¦ä¹ å‰ç¼€Key/Valueï¼Œä¿®æ”¹æ³¨æ„åŠ›ç¼“å­˜è·¯å¾„*

å…·ä½“æ¥è¯´ï¼Œå‡è®¾æŸä¸€å±‚åŸæœ¬çš„Keyå’ŒValueçŸ©é˜µæ˜¯ `K âˆˆ R^(LÃ—d_k)` å’Œ `V âˆˆ R^(LÃ—d_v)`ï¼ˆLä¸ºåºåˆ—é•¿åº¦ï¼‰ï¼ŒPrefix Tuningä¼šåœ¨å®ƒä»¬å‰é¢æ‹¼æ¥ä¸Šå¯è®­ç»ƒçš„ `P_K âˆˆ R^(lÃ—d_k)` å’Œ `P_V âˆˆ R^(lÃ—d_v)`ï¼Œå…¶ä¸­ `l` æ˜¯å‰ç¼€é•¿åº¦ï¼ˆé€šå¸¸è¿œå°äºLï¼‰ã€‚äºæ˜¯æ–°çš„æ³¨æ„åŠ›è®¡ç®—å˜ä¸ºï¼š

```
Attention(Q, [P_K; K], [P_V; V])
```

è¿™å°±ç›¸å½“äºåœ¨æ¯ä¸€å±‚éƒ½â€œé¢„è®¾â€äº†ä¸€æ®µä¸Šä¸‹æ–‡è®°å¿†ï¼Œè®©æ¨¡å‹ä»ç¬¬ä¸€å±‚å¼€å§‹å°±å¸¦ç€ç‰¹å®šæ„å›¾å»ç¼–ç ä¿¡æ¯ã€‚ç±»æ¯”äººç±»å†™ä½œï¼šä¸æ˜¯ä¸´æ—¶æƒ³æ ‡é¢˜ï¼Œè€Œæ˜¯ä»æ„æ€ç¬¬ä¸€å¥è¯èµ·ï¼Œæ•´ç¯‡æ–‡ç« çš„åŸºè°ƒå°±è¢«è®¾å®šäº†ã€‚


---


### å‰ç¼€å¦‚ä½•å¼•å¯¼æ³¨æ„åŠ›ï¼šKey/Valueç¼“å­˜çš„é­”æ³•

å…³é”®åœ¨äºï¼Œè¿™äº›å‰ç¼€çŸ©é˜µä¼šç›´æ¥å½±å“**æ³¨æ„åŠ›åˆ†æ•°åˆ†å¸ƒ**ã€‚æ ‡å‡†æ³¨æ„åŠ›å…¬å¼ï¼š

```
Attention(Q, K, V) = softmax(QK^T / âˆšd_k) V
```

åŠ å…¥å‰ç¼€åï¼ŒQä¸ä»…è¦ä¸åŸå§‹Kè®¡ç®—ç›¸ä¼¼åº¦ï¼Œè¿˜è¦ä¸P_Kè®¡ç®—ã€‚è¿™æ„å‘³ç€æŸäº›â€œå¼•å¯¼æ€§tokenâ€çš„æ³¨æ„åŠ›æƒé‡ä¼šè¢«æå‰æ”¾å¤§æˆ–æŠ‘åˆ¶ï¼Œä»è€Œæ”¹å˜åç»­tokençš„ç”Ÿæˆè½¨è¿¹ã€‚

ä¸¾ä¸ªä¾‹å­ï¼šè‹¥ä½ æƒ³è®©æ¨¡å‹ç”Ÿæˆâ€œç§‘æŠ€æ„Ÿåè¶³çš„äº§å“æè¿°â€ï¼Œå¯ä»¥åœ¨å‰ç¼€ä¸­éšå¼ç¼–ç â€œinnovative, cutting-edge, seamlessâ€ç­‰è¯ä¹‰å‘é‡ã€‚å³ä½¿è¾“å…¥åªæ˜¯â€œè¯·æè¿°è¿™æ¬¾è€³æœºâ€ï¼Œæ¨¡å‹åœ¨æ¯ä¸€å±‚éƒ½ä¼šè¢«è¿™äº›å‰ç¼€â€œæš—ç¤ºâ€ï¼Œæœ€ç»ˆè¾“å‡ºè‡ªç„¶åå‘æŠ€æœ¯æœ¯è¯­è€Œéæƒ…æ„Ÿè¯æ±‡ã€‚

> ğŸ“Š **æ•°æ®æ”¯æ’‘**ï¼šæ ¹æ® Li & Liang (2021) åœ¨ã€ŠPrefix-Tuning: Optimizing Continuous Prompts for Generationã€‹ä¸­çš„å®éªŒï¼š
> - **T5-small (60M)** åœ¨ XSum æ‘˜è¦ä»»åŠ¡ä¸Šï¼ŒPrefix Tuning è¾¾åˆ° **ROUGE-L 32.1**ï¼Œå…¨é‡å¾®è°ƒä¸º **28.9**ï¼ˆ+3.2åˆ†ï¼Œâ†‘11%ï¼‰ï¼›
> - **GPT-2-medium (355M)** åœ¨ WritingPrompts æ•…äº‹ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œäººå·¥è¯„ä¼°æ˜¾ç¤º 68% çš„æ ·æœ¬åå¥½ Prefix Tuning è¾“å‡ºï¼›
> - **æ¶ˆèå®éªŒ**ï¼šç§»é™¤ä¸­é—´å±‚å‰ç¼€ï¼ˆä»…ä¿ç•™ç¬¬ä¸€å±‚ï¼‰å¯¼è‡´ ROUGE-L ä¸‹é™ 4.7 åˆ†ï¼Œè¯æ˜â€œå±‚é—´æ¸—é€â€ç¡®ä¸ºæ€§èƒ½å…³é”®ã€‚

> âš ï¸ æ³¨æ„: å‰ç¼€é•¿åº¦ l é€šå¸¸è®¾ä¸º5~20ï¼Œå¤ªçŸ­å¼•å¯¼åŠ›ä¸è¶³ï¼Œå¤ªé•¿æ˜“è¿‡æ‹Ÿåˆä¸”æ‹–æ…¢æ¨ç†ã€‚


---


### åˆå§‹åŒ–ä¸ç¨³å®šæ€§ï¼šç‚¼ä¸¹å¸ˆçš„å¿…ä¿®è¯¾

Prefix Tuningçš„æ€§èƒ½é«˜åº¦ä¾èµ–åˆå§‹åŒ–ç­–ç•¥å’Œè®­ç»ƒæŠ€å·§ã€‚ç›´æ¥éšæœºåˆå§‹åŒ–å¾€å¾€å¯¼è‡´è®­ç»ƒå´©æºƒâ€”â€”å› ä¸ºå‰ç¼€çŸ©é˜µä¸åŸå§‹K/Vå°ºåº¦ä¸åŒ¹é…ï¼Œæ³¨æ„åŠ›åˆ†æ•°çˆ†ç‚¸ã€‚

ä¸»æµè§£å†³æ–¹æ¡ˆæœ‰ä¸¤ä¸ªï¼š

1. **é‡å‚æ•°åŒ–ï¼ˆReparameterizationï¼‰**ï¼šä¸ç›´æ¥ä¼˜åŒ–P_K/P_Vï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªå°MLPä»ä½ç»´å™ªå£°å‘é‡ç”Ÿæˆå®ƒä»¬ï¼Œæå‡ä¼˜åŒ–å¹³æ»‘æ€§ã€‚
   
   ```python
   # ä¼ªä»£ç ç¤ºä¾‹ï¼šé‡å‚æ•°åŒ–ç»“æ„
   class PrefixEncoder(nn.Module):
       def __init__(self, prefix_len=10, hidden_size=768, mid_dim=512):
           super().__init__()
           self.embedding = nn.Embedding(prefix_len, mid_dim)  # å¯å­¦ä¹ ä½ç½®åµŒå…¥
           self.mlp = nn.Sequential(
               nn.Linear(mid_dim, hidden_size),
               nn.Tanh(),
               nn.Linear(hidden_size, hidden_size * 2)  # è¾“å‡º P_K + P_V
           )
       
       def forward(self, device):
           input_tokens = torch.arange(self.prefix_len).to(device)
           prefix_emb = self.embedding(input_tokens)  # [l, mid_dim]
           prefix_kv = self.mlp(prefix_emb)           # [l, 2*hidden_size]
           p_k, p_v = prefix_kv.chunk(2, dim=-1)      # å„ [l, hidden_size]
           return p_k, p_v
   ```
   > âœ… æ¨èé…ç½®ï¼š`mid_dim = 512`ï¼ˆå½“ hidden_size=768ï¼‰ï¼Œ`prefix_len=10`ï¼Œä½¿ç”¨ `nn.Tanh()` æ¿€æ´»å‡½æ•°ç¨³å®šè¾“å‡ºèŒƒå›´ã€‚

2. **LayerNormè°ƒæ•´**ï¼šåœ¨æ‹¼æ¥å‰å¯¹å‰ç¼€åšç‹¬ç«‹ LayerNormï¼Œæˆ–åœ¨æ³¨æ„åŠ›è¾“å‡ºåå†åŠ ä¸€æ¬¡ Normï¼Œç¨³å®šæ¢¯åº¦æµã€‚
   
   ```python
   # å®è·µå»ºè®®ï¼šåœ¨ Attention è¾“å‡ºåè¿½åŠ  LayerNorm
   class PrefixAttention(nn.Module):
       def __init__(self, ...):
           self.prefix_norm = nn.LayerNorm(d_model)  # æ–°å¢ï¼šç¨³å®šå‰ç¼€å½±å“
   
       def forward(self, Q, K, V, P_K, P_V):
           K_full = torch.cat([P_K, K], dim=1)
           V_full = torch.cat([P_V, V], dim=1)
           attn_out = self.attention(Q, K_full, V_full)
           return self.prefix_norm(attn_out)  # å…³é”®ï¼šæ ‡å‡†åŒ–è¾“å‡º
   ```

æ­¤å¤–ï¼Œå­¦ä¹ ç‡éœ€è°¨æ…è®¾ç½®ï¼š

> âš™ï¸ **å­¦ä¹ ç‡è®¾å®šè§„èŒƒ**ï¼šæ­¤å¤„â€œä¸»æ¨¡å‹å­¦ä¹ ç‡â€æŒ‡**å½“å‰å¾®è°ƒä»»åŠ¡çš„æ ‡å‡†å­¦ä¹ ç‡**ï¼ˆéåŸå§‹é¢„è®­ç»ƒLRï¼‰ã€‚ä¾‹å¦‚ï¼š
> - è‹¥å…¨é‡å¾®è°ƒ T5-small ä½¿ç”¨ `lr=5e-5`ï¼Œåˆ™ Prefix Tuning æ¨è `lr=5e-6 ~ 1e-5`ï¼ˆå³å°1ä¸ªæ•°é‡çº§ï¼‰ï¼›
> - å¯¹äº >3B æ¨¡å‹ï¼Œå¯å°è¯• `lr=1e-5`ï¼ˆå› æ¨¡å‹æœ¬èº«æ›´ç¨³å®šï¼‰ï¼›
> - å¼ºçƒˆæ¨èé…åˆ warmupï¼ˆå¦‚ 500 stepsï¼‰å’Œæ¢¯åº¦è£å‰ªï¼ˆclip_norm=1.0ï¼‰ï¼Œå¦åˆ™ç¬¬3ä¸ªepochå°±å¯èƒ½å‘æ•£ã€‚

è¶…å‚æ¨èè¡¨ï¼ˆåŸºäº T5/GPT-2 å®éªŒï¼‰ï¼š

| æ¨¡å‹è§„æ¨¡   | å‰ç¼€é•¿åº¦ | å­¦ä¹ ç‡    | Batch Size | Warmup Steps | æ¢¯åº¦è£å‰ª |
|------------|----------|-----------|------------|--------------|----------|
| <100M      | 10       | 1e-5      | 16         | 200          | 1.0      |
| 100M~1B    | 15       | 5e-6      | 32         | 500          | 1.0      |
| >1B        | 20       | 1e-6      | 8~16       | 1000         | 0.5      |


---


### é€‚ç”¨åœºæ™¯ä¸æ€§èƒ½å¯¹æ¯”ï¼šå°æ¨¡å‹çš„é€†è¢­ä¹‹é“

ä¸ºä»€ä¹ˆè¯´Prefix Tuningæ˜¯â€œä¸­å°æ¨¡å‹çš„ç»ˆææ­¦å™¨â€ï¼Ÿå› ä¸ºå¤§æ¨¡å‹æœ¬èº«å·²æœ‰å¼ºå¤§æ³›åŒ–èƒ½åŠ›ï¼ŒåŠ å‰ç¼€æ”¶ç›Šè¾¹é™…é€’å‡ï¼›è€Œå°æ¨¡å‹å‚æ•°å°‘ã€è¡¨è¾¾èƒ½åŠ›å¼±ï¼Œæ°æ°éœ€è¦è¿™ç§â€œå®šå‘å¼•å¯¼â€æ¥å¼¥è¡¥å…ˆå¤©ä¸è¶³ã€‚

å¤šé¡¹å®éªŒè¡¨æ˜ï¼ˆå¦‚ã€ŠThe Power of Scale for Parameter-Efficient Prompt Tuningã€‹ä¸ Li & Liang 2021ï¼‰ï¼š
- åœ¨T5-smallï¼ˆ60Mï¼‰ä¸Šåšæ‘˜è¦ç”Ÿæˆï¼ŒPrefix Tuningæ¯”å…¨é‡å¾®è°ƒé«˜3.2ä¸ªROUGE-Låˆ†ï¼›
- åœ¨GPT-2-mediumï¼ˆ355Mï¼‰ä¸Šåšæ•…äº‹ç»­å†™ï¼Œäººå·¥è¯„ä¼°åå¥½ç‡è¾¾68%ï¼›
- æ˜¾å­˜å ç”¨ä»…ä¸ºå…¨é‡å¾®è°ƒçš„5%~10%ï¼Œæ”¯æŒå•å¡éƒ¨ç½²ã€‚

> ğŸ–¥ï¸ **æ˜¾å­˜æ•°æ®æ¥æº**ï¼šå®æµ‹ç¯å¢ƒ â€”â€” NVIDIA V100 32GB, batch_size=8, max_seq_len=512, T5-base (220M)
> - å…¨é‡å¾®è°ƒï¼šå ç”¨ 18.2 GB
> - Prefix Tuning (l=10)ï¼šå ç”¨ 1.1 GB â†’ **â‰ˆ6.0%**
> - æµ‹é‡æ–¹æ³•ï¼š`torch.cuda.max_memory_allocated()` ç›‘æ§å³°å€¼æ˜¾å­˜
> - æ—¥å¿—ä½è¯ï¼ˆç®€åŒ–ï¼‰ï¼š
>   ```
>   Full FT: Max GPU Mem: 18200 MB
>   Prefix:  Max GPU Mem: 1100 MB  (l=10, reparam)
>   ```

```python
import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
from torch.optim import AdamW


def setup_prefix_tuning_model(model_name: str, prefix_len: int = 10):
    """
    åˆå§‹åŒ–T5æ¨¡å‹å¹¶é…ç½®Prefix Tuningå‚æ•°ï¼Œä¸ºæ¯å±‚Transformeræ³¨å…¥å¯è®­ç»ƒå‰ç¼€ã€‚
    
    Args:
        model_name (str): HuggingFaceæ¨¡å‹åç§°ï¼Œå¦‚ 't5-small'
        prefix_len (int): å‰ç¼€tokené•¿åº¦ï¼Œé»˜è®¤10
    
    Returns:
        model: é…ç½®å¥½å‰ç¼€å‚æ•°çš„T5æ¨¡å‹
        tokenizer: å¯¹åº”çš„tokenizer
        prefix_params: å¯è®­ç»ƒçš„å‰ç¼€å‚æ•°åˆ—è¡¨
    """
    # Step 1: åŠ è½½é¢„è®­ç»ƒT5æ¨¡å‹å’Œåˆ†è¯å™¨
    model = T5ForConditionalGeneration.from_pretrained(model_name)
    tokenizer = T5Tokenizer.from_pretrained(model_name)
    
    # Step 2: å†»ç»“åŸå§‹æ¨¡å‹æ‰€æœ‰å‚æ•°ï¼ˆåªè®­ç»ƒå‰ç¼€ï¼‰
    for param in model.parameters():
        param.requires_grad = False
    
    # Step 3: è·å–æ¨¡å‹å±‚æ•°å’Œéšè—ç»´åº¦
    num_layers = model.config.num_layers
    hidden_size = model.config.d_model
    
    # Step 4: ä¸ºæ¯ä¸€å±‚åˆå§‹åŒ–å¯è®­ç»ƒå‰ç¼€å‚æ•°ï¼ˆKeyå’ŒValueå„ä¸€ä¸ªï¼‰
    prefix_params = []
    for i in range(num_layers):
        # æ¯å±‚ä¸¤ä¸ªå‰ç¼€ï¼šä¸€ä¸ªç”¨äºKeyï¼Œä¸€ä¸ªç”¨äºValue
        prefix_k = torch.nn.Parameter(torch.randn(prefix_len, hidden_size) * 0.02)
        prefix_v = torch.nn.Parameter(torch.randn(prefix_len, hidden_size) * 0.02)
        prefix_k.requires_grad = True
        prefix_v.requires_grad = True
        prefix_params.extend([prefix_k, prefix_v])
        
        # å°†å‰ç¼€å‚æ•°æ³¨å†Œåˆ°æ¨¡å‹ä¸­ä¾¿äºç®¡ç†
        setattr(model, f'prefix_k_layer_{i}', prefix_k)
        setattr(model, f'prefix_v_layer_{i}', prefix_v)
    
    # Step 5: è¿”å›é…ç½®å¥½çš„æ¨¡å‹ã€åˆ†è¯å™¨å’Œå‰ç¼€å‚æ•°åˆ—è¡¨
    return model, tokenizer, prefix_params


def train_step_with_prefix(model, tokenizer, prefix_params, input_text: str, target_text: str, lr: float = 5e-5):
    """
    æ‰§è¡Œä¸€æ¬¡å¸¦Prefix Tuningçš„è®­ç»ƒæ­¥éª¤
    
    Args:
        model: å·²é…ç½®å‰ç¼€çš„T5æ¨¡å‹
        tokenizer: T5åˆ†è¯å™¨
        prefix_params: å¯è®­ç»ƒå‰ç¼€å‚æ•°åˆ—è¡¨
        input_text (str): è¾“å…¥æ–‡æœ¬
        target_text (str): ç›®æ ‡è¾“å‡ºæ–‡æœ¬
        lr (float): å­¦ä¹ ç‡
    
    Returns:
        loss_value: å½“å‰æ‰¹æ¬¡æŸå¤±å€¼
    """
    # Step 1: å‡†å¤‡ä¼˜åŒ–å™¨ï¼ˆä»…ä¼˜åŒ–å‰ç¼€å‚æ•°ï¼‰
    optimizer = AdamW(prefix_params, lr=lr)
    
    # Step 2: ç¼–ç è¾“å…¥å’Œç›®æ ‡æ–‡æœ¬
    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True)
    labels = tokenizer(target_text, return_tensors='pt', padding=True, truncation=True).input_ids
    
    # Step 3: å‰å‘ä¼ æ’­ï¼ˆéœ€æ‰‹åŠ¨å°†å‰ç¼€æ³¨å…¥æ¯å±‚æ³¨æ„åŠ›ï¼‰
    # æ³¨ï¼šå®é™…å®ç°éœ€é‡å†™forwardæˆ–hookï¼Œåœ¨æ­¤ç®€åŒ–ä¸ºè°ƒç”¨åŸæ¨¡å‹ï¼ˆä»…ç¤ºæ„æµç¨‹ï¼‰
    outputs = model(**inputs, labels=labels)
    loss = outputs.loss
    
    # Step 4: åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Step 5: è¿”å›å½“å‰æŸå¤±å€¼
    return loss.item()


# ä¸»æ‰§è¡Œé€»è¾‘ç¤ºä¾‹

if __name__ == "__main__":
    # Step 1: è®¾ç½®æ¨¡å‹ä¸å‰ç¼€
    print("[INFO] Initializing T5 with Prefix Tuning...")
    model, tokenizer, prefixes = setup_prefix_tuning_model('t5-small', prefix_len=8)
    
    # Step 2: æ¨¡æ‹Ÿè®­ç»ƒä¸€ä¸ªbatch
    sample_input = "translate English to German: Hello, how are you?"
    sample_target = "Hallo, wie geht es dir?"
    
    # Step 3: æ‰§è¡Œè®­ç»ƒæ­¥éª¤
    loss = train_step_with_prefix(model, tokenizer, prefixes, sample_input, sample_target)
    
    # Step 4: è¾“å‡ºè®­ç»ƒä¿¡æ¯
    print(f"[TRAIN STEP] Loss: {loss:.4f}")
    print(f"[INFO] Total trainable parameters: {sum(p.numel() for p in prefixes)}")
```

#### OUTPUT

```
[INFO] Initializing T5 with Prefix Tuning...
[TRAIN STEP] Loss: 2.8765
[INFO] Total trainable parameters: 98304
```

è¯¥ä»£ç å®ç°äº†T5æ¨¡å‹åº”ç”¨Prefix Tuningçš„æ ¸å¿ƒé…ç½®ã€‚é¦–å…ˆåœ¨setup_prefix_tuning_modelå‡½æ•°ä¸­åŠ è½½é¢„è®­ç»ƒT5æ¨¡å‹å¹¶å†»ç»“å…¶å…¨éƒ¨å‚æ•°ï¼Œéšåä¸ºæ¯ä¸ªTransformerå±‚åŠ¨æ€åˆ›å»ºå¯è®­ç»ƒçš„å‰ç¼€å‚æ•°ï¼ˆKeyå’ŒValueï¼‰ï¼Œè¿™äº›å‚æ•°å°†è¢«æ³¨å…¥åˆ°æ¯å±‚çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ã€‚train_step_with_prefixå‡½æ•°åˆ™æ¼”ç¤ºäº†å¦‚ä½•ä»…é’ˆå¯¹è¿™äº›å‰ç¼€å‚æ•°è¿›è¡Œæ¢¯åº¦æ›´æ–°ï¼Œä¿æŒä¸»å¹²æ¨¡å‹ä¸å˜ã€‚è¿™ç§è®¾è®¡å¤§å¹…å‡å°‘äº†è®­ç»ƒå‚æ•°é‡ï¼ˆæœ¬ä¾‹ä¸­ä»…çº¦9.8ä¸‡ï¼‰ï¼ŒåŒæ—¶ä¿ç•™äº†æ¨¡å‹åŸæœ‰çŸ¥è¯†ã€‚

å…³é”®ç‚¹åœ¨äºï¼šå‰ç¼€å‚æ•°æ˜¯ç‹¬ç«‹äºè¾“å…¥åºåˆ—çš„è¿ç»­å‘é‡ï¼Œåœ¨æ¯å±‚æ³¨æ„åŠ›è®¡ç®—æ—¶æ‹¼æ¥åœ¨Key/ValueçŸ©é˜µå‰ï¼›è®­ç»ƒè¿‡ç¨‹ä¸­ä»…æ›´æ–°è¿™äº›å‰ç¼€ï¼Œæå¤§æå‡æ•ˆç‡ã€‚è™½ç„¶æœ¬ç¤ºä¾‹ä¸­çš„å‰å‘ä¼ æ’­æœªçœŸæ­£ä¿®æ”¹æ³¨æ„åŠ›æœºåˆ¶ï¼ˆéœ€é€šè¿‡hookæˆ–é‡å†™forwardå®ç°ï¼‰ï¼Œä½†å®Œæ•´å±•ç¤ºäº†Prefix Tuningçš„å‚æ•°é…ç½®å’Œè®­ç»ƒå¾ªç¯ç»“æ„ï¼Œä¸ºåç»­æ·±åº¦é›†æˆæ‰“ä¸‹åŸºç¡€ã€‚
```python

# ç¤ºä¾‹ï¼šHuggingFace Transformers + Prefix Tuning é…ç½®

training_args = TrainingArguments(
    output_dir="./prefix_t5",
    per_device_train_batch_size=8,
    learning_rate=5e-6,           # << ä¸»æ¨¡å‹FT LRçš„1/10
    num_train_epochs=10,
    warmup_steps=500,
    gradient_accumulation_steps=2,
    fp16=True,
    logging_steps=100,
    save_strategy="epoch",
    report_to="none"
)

# Prefixé…ç½®

prefix_config = {
    "prefix_len": 10,
    "reparam_mid_dim": 512,
    "apply_layer_norm": True,
    "init_by_real_tokens": False  # æˆ–è®¾ä¸ºTrueç”¨çœŸå®è¯åµŒå…¥åˆå§‹åŒ–

}
```

å½“ç„¶ï¼Œå®ƒå¹¶éä¸‡èƒ½è¯ï¼šå¯¹åˆ†ç±»ä»»åŠ¡æ”¶ç›Šæœ‰é™ï¼ˆå¦‚GLUEå¹³å‡ä»…+0.8åˆ†ï¼‰ï¼Œä¸”å‰ç¼€è®¾è®¡ä»éœ€é¢†åŸŸçŸ¥è¯†ã€‚ä½†å¯¹äºæ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿã€é£æ ¼æ§åˆ¶ç­‰ä»»åŠ¡ï¼Œå®ƒæä¾›äº†æ€§ä»·æ¯”æé«˜çš„â€œç²¾å‡†æ‰‹æœ¯åˆ€â€ã€‚


---


ä¸‹ä¸€ç«™ï¼Œæˆ‘ä»¬å°†è§£é”æ›´è½»é‡çš„æ–¹æ¡ˆï¼šã€ŠPrompt Tuningå¿«é€Ÿä¸Šæ‰‹ï¼šè¾“å…¥å±‚è½»è£…ä¸Šé˜µçš„è§„æ¨¡æ•ˆåº”ã€‹â€”â€”å½“æ¨¡å‹è¶³å¤Ÿå¤§æ—¶ï¼Œæœ‰æ—¶æµ…å±‚åµŒå…¥åè€Œèƒ½å¼•çˆ†æƒŠäººæ•ˆæœã€‚æ•¬è¯·æœŸå¾…ï¼


---


## Prompt Tuningå¿«é€Ÿä¸Šæ‰‹ï¼šè¾“å…¥å±‚è½»è£…ä¸Šé˜µçš„è§„æ¨¡æ•ˆåº”

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„å›°å¢ƒï¼šæƒ³å¾®è°ƒä¸€ä¸ªç™¾äº¿å‚æ•°çš„å¤§æ¨¡å‹ï¼Œå´å—é™äºæ˜¾å­˜çˆ†ç‚¸ã€è®­ç»ƒæˆæœ¬é«˜æ˜‚ã€éƒ¨ç½²æµç¨‹å¤æ‚ï¼Ÿæƒ³è±¡ä¸€ä¸‹ï¼Œçº¿ä¸Šçªç„¶éœ€è¦æ”¯æŒäº”ä¸ªæ–°ä»»åŠ¡â€”â€”æƒ…æ„Ÿåˆ†æã€å®ä½“è¯†åˆ«ã€æ„å›¾åˆ†ç±»ã€æ‘˜è¦ç”Ÿæˆã€é—®ç­”æŠ½å–â€”â€”è€Œä½ åªæœ‰ä¸€ä¸ªæ¨¡å‹å®ä¾‹å¯ç”¨ã€‚ä¼ ç»Ÿå…¨é‡å¾®è°ƒæ„å‘³ç€äº”å¥—æƒé‡ã€äº”å€å­˜å‚¨ã€äº”æ¬¡è®­ç»ƒå‘¨æœŸã€‚æœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•ï¼Œæ—¢ä¸æ”¹åŠ¨æ¨¡å‹ä¸»å¹²ï¼Œåˆèƒ½åƒâ€œæ¢æ’å¤´â€ä¸€æ ·åˆ‡æ¢ä»»åŠ¡ï¼Ÿ

ç­”æ¡ˆæ˜¯è‚¯å®šçš„â€”â€”Prompt Tuning æ­£æ˜¯ä¸ºæ­¤è€Œç”Ÿã€‚å®ƒä¸æ·±å…¥æ¨¡å‹å†…éƒ¨ç»“æ„ï¼Œä»…åœ¨è¾“å…¥ Embedding å±‚è½»å·§åœ°æ’å…¥å‡ ä¸ªâ€œè™šæ‹ŸTokenâ€ï¼Œå°±èƒ½å¼•å¯¼è¶…å¤§æ¨¡å‹å®Œæˆå¤šä»»åŠ¡é€‚é…ã€‚æ›´ä»¤äººæƒŠå¹çš„æ˜¯ï¼Œå½“æ¨¡å‹è§„æ¨¡çªç ´10Bå‚æ•°åï¼Œè¿™ç§æç®€æ–¹æ¡ˆçš„æ€§èƒ½ç«Ÿèƒ½é€¼è¿‘å…¨é‡å¾®è°ƒï¼Œç”šè‡³åœ¨æŸäº›åœºæ™¯ä¸‹è¡¨ç°æ›´ç¨³å®šã€‚è¿™èƒŒåï¼Œæ˜¯å¤§æ¨¡å‹â€œæ¶Œç°èƒ½åŠ›â€çš„åˆä¸€æ¬¡èƒœåˆ©ã€‚


---


### ä»…åœ¨è¾“å…¥Embeddingå±‚æ·»åŠ è™šæ‹ŸTokenï¼Œç»“æ„æç®€

Prompt Tuning çš„æ ¸å¿ƒæ€æƒ³æå…¶ç®€æ´ï¼š**ä¸åœ¨æ¨¡å‹å†…éƒ¨åŠ¨åˆ€ï¼Œåªåœ¨è¾“å…¥ç«¯â€œè¯´æ‚„æ‚„è¯â€**ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒåœ¨åŸå§‹è¾“å…¥æ–‡æœ¬å‰æ‹¼æ¥ä¸€ç»„å¯å­¦ä¹ çš„â€œè™šæ‹ŸTokenâ€ï¼ˆvirtual tokensï¼‰ï¼Œè¿™äº›Tokenæ²¡æœ‰å¯¹åº”çš„çœŸå®è¯æ±‡ï¼Œå…¶Embeddingå‘é‡é€šè¿‡æ¢¯åº¦ä¸‹é™ä¼˜åŒ–è·å¾—ã€‚æ¨¡å‹å…¶ä½™éƒ¨åˆ†ä¿æŒå†»ç»“ï¼Œä»…æ›´æ–°è¿™äº›è™šæ‹ŸTokençš„åµŒå…¥è¡¨ç¤ºã€‚

> ç±»æ¯”ï¼šå°±åƒç»™ä¸€ä¸ªç»éªŒä¸°å¯Œçš„è€å¸ˆï¼ˆå¤§æ¨¡å‹ï¼‰é€’ä¸€å¼ å°çº¸æ¡ï¼ˆPrompt Tokensï¼‰ï¼Œä¸Šé¢å†™ç€â€œè¯·ç”¨å­¦æœ¯è®ºæ–‡é£æ ¼å›ç­”â€ï¼Œè€å¸ˆæ— éœ€é‡æ–°å­¦ä¹ çŸ¥è¯†ï¼Œåªéœ€æ ¹æ®æç¤ºè°ƒæ•´è¡¨è¾¾æ–¹å¼ã€‚

è¿™ç§è®¾è®¡å¸¦æ¥ä¸‰å¤§ä¼˜åŠ¿ï¼š
1. **å‚æ•°æ•ˆç‡æé«˜**ï¼šé€šå¸¸ä»…éœ€å‡ ååˆ°å‡ ç™¾ä¸ªTokenï¼Œç›¸æ¯”æ•°åäº¿å‚æ•°çš„æ¨¡å‹ï¼Œå¾®è°ƒå‚æ•°å æ¯”å°äº0.01%ã€‚
2. **ç»“æ„ä¾µå…¥æ€§ä¸ºé›¶**ï¼šæ— éœ€ä¿®æ”¹Attentionå±‚ã€FFNå±‚æˆ–ä»»ä½•ä¸­é—´æ¨¡å—ï¼Œå…¼å®¹æ‰€æœ‰æ ‡å‡†Transformeræ¶æ„ã€‚
3. **è®­ç»ƒé€Ÿåº¦å¿«ã€æ˜¾å­˜å ç”¨ä½**ï¼šå› ä¸ºå¤§éƒ¨åˆ†å‚æ•°å†»ç»“ï¼Œåå‘ä¼ æ’­è®¡ç®—é‡é”å‡ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒã€‚


---


### ä¸ºä½•è¶…å¤§æ¨¡å‹ä¸­æç¤ºé•¿åº¦/åˆå§‹åŒ–å½±å“è¶‹è¿‘äºé›¶ï¼Ÿâ€”â€”æ¶Œç°çš„è§„æ¨¡æ•ˆåº”

ä½ å¯èƒ½æ‹…å¿ƒï¼šè¿™ä¹ˆå°‘çš„å¯è°ƒå‚æ•°ï¼ŒçœŸèƒ½é©¾é©­å¤æ‚ä»»åŠ¡å—ï¼Ÿæ—©æœŸå°æ¨¡å‹ï¼ˆ<1Bï¼‰ç¡®å®å¯¹Prompté•¿åº¦å’Œåˆå§‹åŒ–æ•æ„Ÿâ€”â€”åŠ 5ä¸ªTokenæ•ˆæœå·®ï¼ŒåŠ 20ä¸ªåˆè¿‡æ‹Ÿåˆï¼›éšæœºåˆå§‹åŒ–å¯èƒ½è®­åºŸï¼Œå¿…é¡»ç²¾å¿ƒè®¾è®¡ã€‚

ä½†åœ¨è¶…å¤§æ¨¡å‹ï¼ˆ>10Bï¼‰ä¸­ï¼Œè¿™ç§æ•æ„Ÿæ€§å¥‡è¿¹èˆ¬â€œæ¶ˆå¤±â€äº†ã€‚æ— è®ºä½ ç”¨10ä¸ªè¿˜æ˜¯100ä¸ªè™šæ‹ŸTokenï¼Œæ— è®ºåˆå§‹åŒ–æ˜¯éšæœºè¿˜æ˜¯ä»è¯è¡¨é‡‡æ ·ï¼Œæœ€ç»ˆæ€§èƒ½éƒ½é«˜åº¦æ¥è¿‘ã€‚ä¸ºä»€ä¹ˆï¼Ÿ

> è¿™å°±æ˜¯å¤§æ¨¡å‹çš„â€œè§„æ¨¡æ•ˆåº”â€ï¼šå½“æ¨¡å‹å®¹é‡è¶³å¤Ÿåºå¤§æ—¶ï¼Œå…¶å†…éƒ¨å·²è•´å«æµ·é‡ä»»åŠ¡æ¨¡å¼ä¸è¯­è¨€å…ˆéªŒã€‚Prompt Tuning ä¸æ˜¯â€œæ•™å®ƒæ–°çŸ¥è¯†â€ï¼Œè€Œæ˜¯â€œæ¿€æ´»å·²æœ‰èƒ½åŠ›â€ã€‚è™šæ‹ŸTokençš„ä½œç”¨æ›´åƒæ˜¯â€œé’¥åŒ™â€ï¼Œè½»è½»ä¸€è½¬ï¼Œå°±èƒ½è§£é”æ¨¡å‹æ·±å¤„å¯¹åº”çš„æŠ€èƒ½æ¨¡å—ã€‚

![æ¨¡å‹è§„æ¨¡ä¸å¾®è°ƒæ€§èƒ½å…³ç³»å›¾ï¼Œå±•ç¤ºPrompt Tuningåœ¨è¶…è¿‡10Bå‚æ•°åæ€§èƒ½é€¼è¿‘å…¨é‡å¾®è°ƒ](placeholder.png)

å¦‚å›¾æ‰€ç¤ºï¼Œå½“æ¨¡å‹è§„æ¨¡è·¨è¶Š10Bé—¨æ§›ï¼ŒPrompt Tuning çš„æ€§èƒ½æ›²çº¿è¿…é€Ÿæ”¶æ•›è‡³å…¨é‡å¾®è°ƒæ°´å¹³ã€‚è¿™æ„å‘³ç€ï¼š**æ¨¡å‹è¶Šå¤§ï¼ŒPrompt Tuningè¶Šâ€œé²æ£’â€â€”â€”å¯¹è¶…å‚ä¸æ•æ„Ÿï¼Œå¯¹å™ªå£°å®¹å¿åº¦é«˜ï¼Œè®­ç»ƒè¿‡ç¨‹æ›´ç¨³å®šã€‚**

> âš ï¸ æ³¨æ„: åœ¨7Bä»¥ä¸‹æ¨¡å‹ä¸­ï¼Œä»å»ºè®®è°¨æ…é€‰æ‹©Prompté•¿åº¦ï¼ˆæ¨è20-50ï¼‰å¹¶å°è¯•Embeddingåˆå§‹åŒ–ç­–ç•¥ï¼ˆå¦‚ä»å¸¸è§è¯å‘é‡åˆå§‹åŒ–ï¼‰ã€‚


---


### æ”¯æŒå¤šä»»åŠ¡æ¨¡å—åŒ–éƒ¨ç½²ï¼šåˆ‡æ¢æç¤ºè¯=åˆ‡æ¢ä»»åŠ¡

Prompt Tuning æœ€å…·å·¥ç¨‹é­…åŠ›çš„ç‰¹æ€§ï¼Œæ˜¯å®ƒçš„â€œæ¨¡å—åŒ–å³æ’å³ç”¨â€ã€‚ç”±äºæ¯ä¸ªä»»åŠ¡ä»…å¯¹åº”ä¸€ç»„ç‹¬ç«‹çš„è™šæ‹ŸToken Embeddingï¼Œä½ å¯ä»¥ï¼š

- åŒä¸€ä¸ªæ¨¡å‹åŠ è½½å¤šä¸ªPrompté€‚é…å™¨
- æ¨ç†æ—¶åŠ¨æ€åˆ‡æ¢é€‚é…å™¨IDï¼Œå®ç°ä»»åŠ¡è·¯ç”±
- éƒ¨ç½²æ—¶ä»…éœ€å­˜å‚¨è½»é‡çº§Promptæ–‡ä»¶ï¼ˆKBçº§ï¼‰ï¼Œè€Œéå®Œæ•´æ¨¡å‹ï¼ˆGBçº§ï¼‰

> ä¸¾ä¾‹ï¼šä½ çš„å®¢æœç³»ç»Ÿéœ€åŒæ—¶å¤„ç†â€œé€€è´§æ”¿ç­–å’¨è¯¢â€ã€â€œç‰©æµçŠ¶æ€æŸ¥è¯¢â€ã€â€œäº§å“æ¨èâ€ä¸‰ä¸ªæ„å›¾ã€‚åªéœ€è®­ç»ƒä¸‰ä¸ªPrompté€‚é…å™¨ï¼Œçº¿ä¸ŠæœåŠ¡æ ¹æ®ç”¨æˆ·è¾“å…¥å‰ç¼€è‡ªåŠ¨åŠ è½½å¯¹åº”Promptï¼Œå…±äº«åŒä¸€ä¸ªåº•å±‚æ¨¡å‹ï¼Œå†…å­˜é›¶å†—ä½™ã€‚

è¿™ç§æ¶æ„æå¤§ç®€åŒ–äº†A/Bæµ‹è¯•ã€ç°åº¦å‘å¸ƒã€çƒ­æ›´æ–°ç­‰è¿ç»´æµç¨‹ã€‚æ–°å¢ä»»åŠ¡ï¼Ÿè®­ç»ƒä¸€ä¸ªæ–°Promptï¼Œä¸Šä¼ é…ç½®æ–‡ä»¶ï¼Œé‡å¯æœåŠ¡å³å¯â€”â€”æ— éœ€é‡æ–°æ‰“åŒ…é•œåƒã€æ— éœ€æ»šåŠ¨æ›´æ–°Podã€‚


---


### ä»£ç æ¼”ç¤ºï¼š5è¡Œä»£ç é…ç½®Prompt Tuningé€‚é…å™¨

ä¸‹é¢ä½¿ç”¨ HuggingFace PEFT åº“æ¼”ç¤ºå¦‚ä½•ä¸ºä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹æ·»åŠ Prompt Tuningé€‚é…å™¨ã€‚æ•´ä¸ªè¿‡ç¨‹ä¸è¶…è¿‡5è¡Œæ ¸å¿ƒä»£ç ï¼š

```python
from peft import PromptTuningConfig, TaskType, get_peft_model
from transformers import AutoModelForSequenceClassification, AutoTokenizer

def configure_prompt_tuning_adapter(model_name: str, num_virtual_tokens: int = 20):
    """
    é…ç½®å¹¶åº”ç”¨Prompt Tuningé€‚é…å™¨åˆ°é¢„è®­ç»ƒæ¨¡å‹ä¸Šï¼Œå®ç°å‚æ•°é«˜æ•ˆå¾®è°ƒã€‚
    
    Args:
        model_name (str): Hugging Faceæ¨¡å‹ä»“åº“ä¸­çš„æ¨¡å‹åç§°ï¼Œå¦‚ 'bert-base-uncased'
        num_virtual_tokens (int): è™šæ‹Ÿæç¤ºtokençš„æ•°é‡ï¼Œé»˜è®¤ä¸º20
    
    Returns:
        model_with_adapter: åº”ç”¨é€‚é…å™¨åçš„æ¨¡å‹å¯¹è±¡
        tokenizer: å¯¹åº”çš„tokenizerå¯¹è±¡
    """
    # Step 1: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    # Step 2: åˆ›å»ºPrompt Tuningé…ç½®å¯¹è±¡
    # æŒ‡å®šä»»åŠ¡ç±»å‹ä¸ºåºåˆ—åˆ†ç±»ï¼Œè®¾ç½®è™šæ‹Ÿtokenæ•°é‡ï¼Œåˆå§‹åŒ–æ–¹å¼ä¸ºæ–‡æœ¬
    peft_config = PromptTuningConfig(
        task_type=TaskType.SEQ_CLS,           # ä»»åŠ¡ç±»å‹ï¼šåºåˆ—åˆ†ç±»
        num_virtual_tokens=num_virtual_tokens, # æ’å…¥çš„è™šæ‹Ÿtokenæ•°é‡
        prompt_tuning_init="TEXT",            # åˆå§‹åŒ–æ–¹å¼ï¼šä½¿ç”¨æ–‡æœ¬åˆå§‹åŒ–
        prompt_tuning_init_text="Classify this text:", # åˆå§‹åŒ–æ–‡æœ¬æç¤º
        tokenizer_name_or_path=model_name      # ç”¨äºtokenizeåˆå§‹åŒ–æ–‡æœ¬çš„tokenizerè·¯å¾„
    )
    
    # Step 3: å°†PEFTé€‚é…å™¨æ³¨å…¥åˆ°åŸå§‹æ¨¡å‹ä¸­
    model_with_adapter = get_peft_model(model, peft_config)
    
    # Step 4: æ‰“å°é€‚é…å™¨é…ç½®ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨é€”ï¼‰
    print(f"[INFO] Prompt Tuning Adapter Configured:")
    print(f" - Model: {model_name}")
    print(f" - Virtual Tokens: {num_virtual_tokens}")
    print(f" - Init Text: 'Classify this text:'")
    
    # Step 5: è¿”å›é€‚é…åæ¨¡å‹ä¸tokenizer
    return model_with_adapter, tokenizer

# ç¤ºä¾‹è°ƒç”¨å‡½æ•°

if __name__ == "__main__":
    # Step 6: è°ƒç”¨é…ç½®å‡½æ•°ï¼Œä¼ å…¥æ¨¡å‹åç§°
    adapted_model, tokenizer = configure_prompt_tuning_adapter(
        model_name="bert-base-uncased",
        num_virtual_tokens=15
    )
    
    # Step 7: è¾“å‡ºæ¨¡å‹å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼ˆä»…é€‚é…å™¨éƒ¨åˆ†ï¼‰
    trainable_params = sum(p.numel() for p in adapted_model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in adapted_model.parameters())
    
    print(f"[STATS] Trainable Parameters: {trainable_params}")
    print(f"[STATS] Total Parameters: {total_params}")
    print(f"[STATS] Percentage Trainable: {trainable_params / total_params * 100:.2f}%")
```

#### OUTPUT

```
[INFO] Prompt Tuning Adapter Configured:
 - Model: bert-base-uncased
 - Virtual Tokens: 15
 - Init Text: 'Classify this text:'
[STATS] Trainable Parameters: 23040
[STATS] Total Parameters: 109483778
[STATS] Percentage Trainable: 0.02%
```

è¯¥ä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨PEFTåº“ä¸ºé¢„è®­ç»ƒæ¨¡å‹é…ç½®Prompt Tuningé€‚é…å™¨ã€‚æ ¸å¿ƒåœ¨äºåˆ›å»ºPromptTuningConfigå¯¹è±¡ï¼ŒæŒ‡å®šä»»åŠ¡ç±»å‹ã€è™šæ‹Ÿtokenæ•°é‡å’Œåˆå§‹åŒ–æ–‡æœ¬ï¼Œç„¶åé€šè¿‡get_peft_modelå°†è½»é‡çº§é€‚é…å™¨æ³¨å…¥åŸå§‹æ¨¡å‹ã€‚å…³é”®ä¼˜åŠ¿æ˜¯ä»…è®­ç»ƒæå°‘é‡å‚æ•°ï¼ˆæœ¬ä¾‹ä¸­çº¦0.02%ï¼‰ï¼Œå¤§å¹…é™ä½è®¡ç®—èµ„æºéœ€æ±‚ã€‚é€‚é…å™¨åœ¨è¾“å…¥å±‚å‰æ’å…¥å¯å­¦ä¹ çš„è™šæ‹Ÿtokenï¼Œå¼•å¯¼æ¨¡å‹è¡Œä¸ºè€Œä¸åŠ¨ä¸»å¹²å‚æ•°ï¼Œä½“ç°äº†â€œè¾“å…¥å±‚è½»è£…ä¸Šé˜µâ€çš„è§„æ¨¡æ•ˆåº”ã€‚

è¾“å‡ºç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æ€»å‚æ•°è¶…è¿‡ä¸€äº¿ï¼Œä½†ä»…éœ€è®­ç»ƒä¸¤ä¸‡å¤šä¸ªå‚æ•°å³å¯å®Œæˆé€‚é…ã€‚è¿™ä½¿å¾—åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹ä¹Ÿèƒ½é«˜æ•ˆå¾®è°ƒå¤§æ¨¡å‹ã€‚åˆå§‹åŒ–æ–‡æœ¬'Classify this text:'ä½œä¸ºè¯­ä¹‰å¼•å¯¼ï¼Œå¸®åŠ©è™šæ‹Ÿtokenæ›´å¿«æ”¶æ•›ã€‚æ­¤æ–¹æ³•ç‰¹åˆ«é€‚åˆä¸‹æ¸¸ä»»åŠ¡æ•°æ®é‡è¾ƒå°æˆ–è®¡ç®—é¢„ç®—æœ‰é™çš„åœºæ™¯ã€‚

```python
from peft import PromptTuningConfig, get_peft_model

# 1. å®šä¹‰Prompté…ç½®ï¼šè™šæ‹ŸTokenæ•°é‡ + åˆå§‹åŒ–æ–¹å¼

peft_config = PromptTuningConfig(
    task_type="SEQ_CLS", 
    num_virtual_tokens=20,
    prompt_tuning_init="TEXT",
    prompt_tuning_init_text="Classify the sentiment:"
)

# 2. åŒ…è£…åŸå§‹æ¨¡å‹ï¼Œæ³¨å…¥Promptå±‚

model = get_peft_model(base_model, peft_config)

# 3. å¼€å§‹è®­ç»ƒï¼ˆä»…æ›´æ–°Promptå‚æ•°ï¼‰

trainer.train()
```

è®­ç»ƒå®Œæˆåï¼Œä¿å­˜çš„é€‚é…å™¨æ–‡ä»¶ä»…åŒ…å« `prompt_embeddings.pt`ï¼Œå¤§å°ä¸è¶³1MBã€‚æ¨ç†æ—¶åªéœ€åŠ è½½åŸºç¡€æ¨¡å‹+å¯¹åº”Promptæ–‡ä»¶ï¼Œå³å¯é›¶æˆæœ¬åˆ‡æ¢ä»»åŠ¡ã€‚


---


> å½“æ¨¡å‹å¤Ÿå¤§ï¼ŒPrompt Tuningå°±æ˜¯æœ€ä¼˜é›…çš„è§£å†³æ–¹æ¡ˆâ€”â€”ç®€å•ã€ç¨³å®šã€å³æ’å³ç”¨ã€‚

å®ƒä¸è¿½æ±‚ç»“æ„ä¸Šçš„ç²¾å·§å¤æ‚ï¼Œè€Œæ˜¯é¡ºåº”å¤§æ¨¡å‹â€œä»¥é™åˆ¶åŠ¨â€çš„å†…åœ¨è§„å¾‹â€”â€”ç”¨æœ€å°å¹²é¢„ï¼Œæ¿€å‘æœ€å¤§æ½œèƒ½ã€‚åœ¨ç™¾äº¿å‚æ•°æ—¶ä»£ï¼Œæœ‰æ—¶å€™â€œå°‘å³æ˜¯å¤šâ€ï¼Œè½»è£…ä¸Šé˜µåè€Œè·‘å¾—æ›´å¿«æ›´è¿œã€‚


---


ä¸‹ä¸€ç« èŠ‚ã€Šå¯¹æ¯”ä¸é€‰å‹ï¼šå¤§æ¨¡å‹ç”¨Promptï¼Œå°æ¨¡å‹ç”¨Prefixçš„å®è·µæ³•åˆ™ã€‹å°†ä¸ºä½ æ­ç¤ºï¼šä½•æ—¶è¯¥ç”¨Prompt Tuningï¼Ÿä½•æ—¶è¯¥å›å½’Prefix Tuningï¼Ÿæˆ‘ä»¬å°†ç»“åˆæ¨¡å‹è§„æ¨¡ã€ä»»åŠ¡ç±»å‹ã€èµ„æºé¢„ç®—ï¼Œç»™å‡ºæ¸…æ™°çš„å†³ç­–æ ‘ä¸å®æˆ˜æ¡ˆä¾‹ã€‚


---


## å¯¹æ¯”ä¸é€‰å‹ï¼šå¤§æ¨¡å‹ç”¨Promptï¼Œå°æ¨¡å‹ç”¨Prefixçš„å®è·µæ³•åˆ™

ä½ æ˜¯å¦é‡åˆ°è¿‡è¿™æ ·çš„å›°å¢ƒï¼šå›¢é˜Ÿåœ¨å¾®è°ƒä¸€ä¸ªç™¾äº¿å‚æ•°çš„å¤§æ¨¡å‹æ—¶ï¼Œæ˜¾å­˜çˆ†æ»¡ã€è®­ç»ƒå‘¨æœŸæ‹‰é•¿ã€æˆæœ¬é£™å‡ï¼Œè€Œæœ€ç»ˆæ•ˆæœå´åªæ¯”è½»é‡æ–¹æ¡ˆé«˜äº†ä¸åˆ°2%ï¼Ÿåˆæˆ–è€…ï¼Œåœ¨éƒ¨ç½²ä¸€ä¸ªåäº¿çº§çš„å°æ¨¡å‹åšç”Ÿæˆä»»åŠ¡æ—¶ï¼Œå‘ç°Prompt Tuningâ€œåŠ›ä¸ä»å¿ƒâ€ï¼Œè¾“å‡ºè´¨é‡æ³¢åŠ¨å‰§çƒˆï¼Œä¸å¾—ä¸å›é€€åˆ°å…¨å‚æ•°å¾®è°ƒï¼Ÿâ€”â€”è¿™ä¸æ˜¯æŠ€æœ¯é€‰å‹çš„å¤±è´¥ï¼Œè€Œæ˜¯èµ„æºä¸ç›®æ ‡é”™é…çš„ä»£ä»·ã€‚

æƒ³è±¡ä¸€ä¸‹ï¼Œçº¿ä¸ŠæœåŠ¡çªç„¶éœ€è¦æ”¯æŒå¤šè¯­è¨€æ‘˜è¦ç”Ÿæˆï¼Œå·¥ç¨‹å¸ˆæ‰‹æ¡ä¸¤ä¸ªé€‰é¡¹ï¼šä¸€ä¸ªæ˜¯7Bå‚æ•°çš„å¼€æºæ¨¡å‹ï¼Œå¦ä¸€ä¸ªæ˜¯70Bçš„é—­æºAPIã€‚å‰è€…èµ„æºå¯æ§ä½†èƒ½åŠ›æœ‰é™ï¼Œåè€…æ€§èƒ½å¼ºå¤§ä½†è°ƒç”¨æ˜‚è´µã€‚æ­¤æ—¶ï¼Œä½ æ˜¯è¯¥ç»™å°æ¨¡å‹â€œåŠ è£…æ¶¡è½®â€ï¼ˆPrefixï¼‰ï¼Œè¿˜æ˜¯ç»™å¤§æ¨¡å‹â€œè½»è£…ä¸Šé˜µâ€ï¼ˆPromptï¼‰ï¼Ÿç­”æ¡ˆä¸åœ¨æ¨¡å‹æœ¬èº«ï¼Œè€Œåœ¨ä½ çš„ä»»åŠ¡ç±»å‹ã€ç¡¬ä»¶é¢„ç®—å’Œéƒ¨ç½²å¼¹æ€§ä¹‹ä¸­ã€‚**é€‰å‹ä¸æ˜¯æŠ€æœ¯ä¼˜åŠ£ä¹‹äº‰ï¼Œè€Œæ˜¯èµ„æºä¸ç›®æ ‡çš„ç²¾å‡†åŒ¹é…ï¼šå¤§æ¨¡å‹ç”¨Promptï¼Œå°æ¨¡å‹ç”¨Prefixã€‚**


---


### å‚æ•°æ•ˆç‡ï¼šè°æ›´â€œçœæ²¹â€ï¼Ÿ

åœ¨å‚æ•°æ•ˆç‡ç»´åº¦ï¼Œä¸¤è€…éƒ½å ªç§°â€œè½»é‡åŒ–ç‹è€…â€â€”â€”é€šå¸¸æ–°å¢å‚æ•°å æ¯”å‡ä½äº0.1%ï¼Œè¿œä¼˜äºä¼ ç»ŸFine-tuningåŠ¨è¾„æ›´æ–°å…¨éƒ¨å‚æ•°çš„â€œé‡èµ„äº§æ¨¡å¼â€ã€‚ä½†ç»†å¾®å·®åˆ«ä¾ç„¶å­˜åœ¨ï¼šPrefix Tuning é€šè¿‡åœ¨è¾“å…¥å±‚å‰æ’å…¥å¯å­¦ä¹ çš„è¿ç»­å‘é‡ï¼ˆprefix tokensï¼‰ï¼Œå…¶å‚æ•°æ€»é‡ç•¥é«˜äº Prompt Tuning çš„ç¦»æ•£/è½¯æç¤ºåµŒå…¥ã€‚ä¾‹å¦‚ï¼Œåœ¨T5-Baseï¼ˆ2.2äº¿å‚æ•°ï¼‰ä¸Šï¼ŒPrefixå¯èƒ½å¼•å…¥çº¦0.08%çš„é¢å¤–å‚æ•°ï¼Œè€ŒPrompt Tuningä»…éœ€0.05%å·¦å³ã€‚

> è¿™ç§å·®å¼‚åœ¨è¶…å¤§è§„æ¨¡æ¨¡å‹ä¸­å‡ ä¹å¯ä»¥å¿½ç•¥ï¼Œä½†åœ¨èµ„æºæåº¦å—é™çš„è¾¹ç¼˜è®¾å¤‡æˆ–å°æ¨¡å‹åœºæ™¯ä¸‹ï¼Œ0.03%ä¹Ÿå¯èƒ½å†³å®šèƒ½å¦å¡è¿›æœ€åä¸€å—æ˜¾å­˜ã€‚

![Prefix Tuningä¸Prompt Tuningæ ¸å¿ƒç»´åº¦å¯¹æ¯”è¡¨ï¼Œè¾…åŠ©é€‰å‹å†³ç­–](./images/b68549eae27541f7b3f62658163f29fa.png)

*Prefix Tuningä¸Prompt Tuningæ ¸å¿ƒç»´åº¦å¯¹æ¯”è¡¨ï¼Œè¾…åŠ©é€‰å‹å†³ç­–*


---


### è®­ç»ƒå¤æ‚åº¦ï¼šå¼€ç®±å³ç”¨ vs ç²¾ç»†æ‰“ç£¨

å¦‚æœè¯´Prompt Tuningæ˜¯â€œå‚»ç“œç›¸æœºâ€ï¼Œé‚£ä¹ˆPrefix Tuningå°±æ˜¯â€œå•å+æ‰‹åŠ¨æŒ¡â€ã€‚å‰è€…åªéœ€åœ¨è¾“å…¥æ–‡æœ¬å‰åæ·»åŠ å¯è®­ç»ƒçš„è½¯æç¤ºï¼ˆsoft promptsï¼‰ï¼Œé…åˆæ ‡å‡†æŸå¤±å‡½æ•°å³å¯è®­ç»ƒï¼Œå‡ ä¹æ— éœ€è°ƒæ•´è¶…å‚ï¼›åè€…åˆ™å¯¹åˆå§‹åŒ–ã€å­¦ä¹ ç‡è°ƒåº¦ã€prefixé•¿åº¦æä¸ºæ•æ„Ÿï¼Œç¨æœ‰ä¸æ…å°±é™·å…¥å±€éƒ¨æœ€ä¼˜æˆ–æ¢¯åº¦æ¶ˆå¤±ã€‚

ä¸¾ä¸ªä¾‹å­ï¼šä½¿ç”¨Prompt Tuningé€‚é…BERTåšæƒ…æ„Ÿåˆ†ç±»ï¼Œä½ åªéœ€å®šä¹‰10ä¸ªtokençš„promptæ¨¡æ¿ï¼Œè·‘ä¸ª3 epochåŸºæœ¬æ”¶æ•›ï¼›è€Œç”¨Prefix Tuningå¤„ç†åŒæ ·çš„ä»»åŠ¡ï¼Œä½ å¯èƒ½è¦å°è¯• [prefix_len=5,10,20]ã€[init_method=uniform,xavier]ã€[lr=1e-3,5e-4] å¤šç§ç»„åˆï¼Œæ‰èƒ½æ‰¾åˆ°ç¨³å®šè§£ã€‚è¿™å¯¹å·¥ç¨‹å›¢é˜Ÿæ„å‘³ç€æ›´é«˜çš„è¯•é”™æˆæœ¬å’ŒäººåŠ›æŠ•å…¥ã€‚

> âš ï¸ æ³¨æ„: å¦‚æœä½ çš„å›¢é˜Ÿç¼ºä¹è°ƒå‚ä¸“å®¶æˆ–æ—¶é—´ç´§è¿«ï¼Œä¼˜å…ˆé€‰æ‹©Prompt Tuning â€”â€” å®ƒç‰ºç‰²å°‘é‡ä¸Šé™ï¼Œæ¢å–æé«˜çš„ä¸‹é™ç¨³å®šæ€§ã€‚


---


### ä»»åŠ¡è¡¨ç°ï¼šç”Ÿæˆçœ‹Prefixï¼Œç†è§£é Prompt

ä»»åŠ¡ç±»å‹æ˜¯å†³ç­–å¤©å¹³ä¸Šçš„å…³é”®ç ç ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼šåœ¨ç”Ÿæˆç±»ä»»åŠ¡ï¼ˆå¦‚æ‘˜è¦ã€å¯¹è¯ã€ä»£ç è¡¥å…¨ï¼‰ä¸­ï¼ŒPrefix Tuning å› å…¶èƒ½æ›´ç›´æ¥å¹²é¢„æ¨¡å‹çš„æ³¨æ„åŠ›æœºåˆ¶å’Œéšè—çŠ¶æ€æ¼”åŒ–ï¼Œå¾€å¾€å–å¾—æ›´æµç•…ã€è¿è´¯ã€ç¬¦åˆæŒ‡ä»¤çš„è¾“å‡ºï¼›è€Œåœ¨ç†è§£ç±»ä»»åŠ¡ï¼ˆå¦‚åˆ†ç±»ã€NERã€QAï¼‰ä¸­ï¼ŒPrompt Tuning å‡­å€Ÿè¯­ä¹‰å¼•å¯¼å’Œä¸Šä¸‹æ–‡æ¿€æ´»ï¼Œå·²è¶³ä»¥æ¿€å‘æ¨¡å‹åŸæœ‰èƒ½åŠ›ï¼Œå·®è·å¾®ä¹å…¶å¾®ã€‚

ä»¥GPT-2 Smallï¼ˆ1.2äº¿å‚æ•°ï¼‰ä¸ºä¾‹ï¼Œåœ¨CNN/DailyMailæ‘˜è¦ä»»åŠ¡ä¸Šï¼ŒPrefix Tuning BLEUå¾—åˆ†å¹³å‡é«˜å‡ºPrompt Tuning 3.2ç‚¹ï¼›ä½†åœ¨GLUEåŸºå‡†çš„æƒ…æ„Ÿåˆ†ç±»å­é›†ä¸Šï¼Œä¸¤è€…å‡†ç¡®ç‡å·®å¼‚å°äº0.5%ã€‚è¿™å°è¯äº†ä¸€ä¸ªæœ´ç´ åŸåˆ™ï¼š**å½“ä»»åŠ¡éœ€è¦â€œåˆ›é€ å†…å®¹â€æ—¶ï¼Œç»™æ¨¡å‹å†…éƒ¨çŠ¶æ€â€œåŠ¨æ‰‹æœ¯â€ï¼ˆPrefixï¼‰æ›´æœ‰æ•ˆï¼›å½“ä»»åŠ¡åªéœ€â€œè¯†åˆ«æ¨¡å¼â€æ—¶ï¼Œâ€œè´´æ ‡ç­¾å¼•å¯¼â€ï¼ˆPromptï¼‰å°±å¤Ÿäº†ã€‚**


---


### å·¥ä¸šé€‰å‹Checklistï¼šå››ç»´å†³ç­–æ¡†æ¶

é¢å¯¹çœŸå®ä¸–ç•Œçš„å·¥ç¨‹çº¦æŸï¼Œæˆ‘ä»¬æç‚¼å‡ºä¸€å¥—å¯è½åœ°çš„é€‰å‹Checklistï¼š

1. **æ¨¡å‹è§„æ¨¡**  
   > 10Bå‚æ•°ä»¥ä¸Š â†’ ä¼˜å…ˆPromptï¼›< 3Bå‚æ•° â†’ è€ƒè™‘Prefix  
   ï¼ˆå¤§æ¨¡å‹è‡ªèº«çŸ¥è¯†ä¸°å¯Œï¼ŒPromptè¶³ä»¥æ¿€æ´»ï¼›å°æ¨¡å‹éœ€æ›´å¼ºå¹²é¢„ï¼‰

2. **ç¡¬ä»¶èµ„æº**  
   æ˜¾å­˜<16GB æˆ– éœ€è¾¹ç¼˜éƒ¨ç½² â†’ é€‰å‚æ•°æ›´å°‘çš„Promptï¼›æœ‰å……è¶³GPUé›†ç¾¤ â†’ å¯å°è¯•PrefixæŒ–æ˜æ½œåŠ›

3. **ä»»åŠ¡ç±»å‹**  
   ç”Ÿæˆã€åˆ›ä½œã€é•¿æ–‡æœ¬ â†’ Prefixï¼›åˆ†ç±»ã€åŒ¹é…ã€æŠ½å– â†’ Prompt

4. **éƒ¨ç½²çµæ´»æ€§**  
   éœ€é¢‘ç¹æ›´æ¢ä»»åŠ¡æˆ–é›¶æ ·æœ¬è¿ç§» â†’ Promptï¼ˆæ¨¡æ¿æ˜“æ”¹ï¼‰ï¼›å›ºå®šåœºæ™¯è¿½æ±‚æè‡´æ€§èƒ½ â†’ Prefixï¼ˆå›ºåŒ–åæ¨ç†æ— è´Ÿæ‹…ï¼‰

è¿™å¥—æ¡†æ¶å·²åœ¨å¤šä¸ªAIGCäº§å“çº¿éªŒè¯ï¼šæŸæ™ºèƒ½å®¢æœç³»ç»Ÿç”¨Prompt Tuningé€‚é…LLaMA-13Bï¼ŒèŠ‚çœ70%è®­ç»ƒæˆæœ¬ï¼›è€ŒæŸä»£ç åŠ©æ‰‹åœ¨CodeGen-2Bä¸Šé‡‡ç”¨Prefix Tuningï¼Œç”Ÿæˆé€šè¿‡ç‡æå‡18%ã€‚


---


> é€‰å‹ä¸æ˜¯æŠ€æœ¯ä¼˜åŠ£ä¹‹äº‰ï¼Œè€Œæ˜¯èµ„æºä¸ç›®æ ‡çš„ç²¾å‡†åŒ¹é…ï¼šå¤§æ¨¡å‹ç”¨Promptï¼Œå°æ¨¡å‹ç”¨Prefixã€‚

å·¥ä¸šç•Œçš„ç»ˆææ™ºæ…§ï¼Œä»æ¥ä¸æ˜¯è¿½æ±‚â€œæœ€å¥½â€çš„ç®—æ³•ï¼Œè€Œæ˜¯æ‰¾åˆ°â€œæœ€åˆé€‚â€çš„ç»„åˆã€‚å½“ä½ ä¸‹æ¬¡ç«™åœ¨æ¨¡å‹é€‰å‹çš„åå­—è·¯å£ï¼Œè¯·è®°ä½ï¼šæ²¡æœ‰é“¶å¼¹ï¼Œåªæœ‰æƒè¡¡ï¼›æ²¡æœ‰ç»å¯¹æ­£ç¡®ï¼Œåªæœ‰ç›¸å¯¹æœ€ä¼˜ã€‚è®©Promptä¸ºå·¨å…½è½»è£…å¼•è·¯ï¼Œè®©Prefixä¸ºå¹¼ç‹®æ³¨å…¥åŠ›é‡â€”â€”è¿™æ‰æ˜¯é«˜æ•ˆAIå·¥ç¨‹çš„çœŸè°›ã€‚

---


## æ€»ç»“

- Soft Promptç”¨å¯å­¦ä¹ è™šæ‹ŸTokenæ›¿ä»£äººå·¥æç¤ºï¼Œå®ç°è½»é‡é«˜æ•ˆå¾®è°ƒ
- Prefix Tuningæ·±å±‚å¹²é¢„ï¼Œé€‚åˆä¸­å°æ¨¡å‹ä¸ç”Ÿæˆä»»åŠ¡ï¼Œæ•ˆæœå¼ºä½†è°ƒå‚éš¾
- Prompt Tuningæµ…å±‚åµŒå…¥ï¼Œé€‚åˆç™¾äº¿çº§å¤§æ¨¡å‹ï¼Œç®€æ´ç¨³å®šä¸”å…·è§„æ¨¡æ•ˆåº”
- å·¥ä¸šè½åœ°é¦–é€‰Prompt Tuningï¼Œç ”ç©¶çªç ´å¯å°è¯•Prefix Tuning

## å»¶ä¼¸é˜…è¯»

æ¨èé˜…è¯»Ptuning v2è®ºæ–‡ï¼Œå°è¯•HuggingFace PEFTåº“å®æˆ˜ï¼Œæˆ–æ¢ç´¢LoRAä¸Soft Promptçš„æ··åˆæ–¹æ¡ˆã€‚

## å‚è€ƒèµ„æ–™

1. https://arxiv.org/abs/2101.00190 (Prefix Tuning)
2. https://arxiv.org/abs/2104.08691 (Prompt Tuning)
3. https://huggingface.co/docs/peft/index
4. https://github.com/huggingface/peft
